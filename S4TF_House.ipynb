{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "// %install-swiftpm-flags -c release\n",
    "// %install '.package(url: \"https://github.com/JacopoMangiavacchi/SwiftCoreMLTools.git\", from: \"0.0.5\")' SwiftCoreMLTools\n",
    "// %install '.package(url: \"https://github.com/dduan/Just.git\", from: \"0.8.0\")' Just"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TO4FT9bUohHx"
   },
   "outputs": [],
   "source": [
    "import Foundation\n",
    "import TensorFlow\n",
    "// import SwiftCoreMLTools\n",
    "// import Just"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Download\n",
    "\n",
    "Boston house prices dataset\n",
    "---------------------------\n",
    "\n",
    "**Data Set Characteristics:**  \n",
    "\n",
    "    :Number of Instances: 506 \n",
    "\n",
    "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
    "\n",
    "    :Attribute Information (in order):\n",
    "        - CRIM     per capita crime rate by town\n",
    "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "        - INDUS    proportion of non-retail business acres per town\n",
    "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "        - NOX      nitric oxides concentration (parts per 10 million)\n",
    "        - RM       average number of rooms per dwelling\n",
    "        - AGE      proportion of owner-occupied units built prior to 1940\n",
    "        - DIS      weighted distances to five Boston employment centres\n",
    "        - RAD      index of accessibility to radial highways\n",
    "        - TAX      full-value property-tax rate per ten thousand dollars\n",
    "        - PTRATIO  pupil-teacher ratio by town\n",
    "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "        - LSTAT    % lower status of the population\n",
    "        - MEDV     Median value of owner-occupied homes in a thousand dollar\n",
    "\n",
    "    :Missing Attribute Values: None\n",
    "\n",
    "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
    "\n",
    "This is a copy of UCI ML housing dataset.\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "// if let cts = Just.get(URL(string: \"https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\")!).content {\n",
    "//     try! cts.write(to: URL(fileURLWithPath:\"../data/housing.csv\"))\n",
    "// }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "let data = try String(contentsOfFile:\"./data/housing.csv\", encoding: String.Encoding.utf8)\n",
    "let dataRecords: [[Float]] = data.split(separator: \"\\n\").map{ String($0).split(separator: \" \").compactMap{ Float(String($0)) } }\n",
    "\n",
    "let numRecords = dataRecords.count\n",
    "let numColumns = dataRecords[0].count\n",
    "\n",
    "let dataFeatures = dataRecords.map{ Array($0[0..<numColumns-1]) }\n",
    "let dataLabels = dataRecords.map{ Array($0[(numColumns-1)...]) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Numerical Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "let categoricalColumns = [3, 8]\n",
    "let numericalColumns = [0, 1, 2, 4, 5, 6, 7, 9, 10, 11, 12]\n",
    "let numCategoricalFeatures = categoricalColumns.count\n",
    "let numNumericalFeatures = numericalColumns.count\n",
    "let numLabels = 1\n",
    "\n",
    "assert(numColumns == numCategoricalFeatures + numNumericalFeatures + 1)\n",
    "\n",
    "// Get Categorical Features\n",
    "let allCategoriesValues = dataFeatures.map{ row in categoricalColumns.map{ Int32(row[$0]) } }\n",
    "                                .reduce(into: Array(repeating: [Int32](), count: 2)){ total, value in\n",
    "                                    total[0].append(value[0])\n",
    "                                    total[1].append(value[1]) }\n",
    "                                .map{ Set($0).sorted() }\n",
    "\n",
    "let embeddingSizes = allCategoriesValues.map{ $0.count }\n",
    "\n",
    "let categoricalFeatures = dataFeatures.map{ row in categoricalColumns.map{ Int32(row[$0]) } }\n",
    "let oneHotCategoricalFeatures:[[[Int32]]] = categoricalFeatures.map{ catArray in\n",
    "    var oneHotArray = [[Int32]]()\n",
    "    \n",
    "    for i in 0..<catArray.count {\n",
    "        var oneHot = Array(repeating: Int32(0), count: allCategoriesValues[i].count)\n",
    "        if let pos = allCategoriesValues[i].firstIndex(where: { $0 == catArray[i] }){\n",
    "            oneHot[pos] = 1\n",
    "        }\n",
    "        oneHotArray.append(oneHot)\n",
    "    }\n",
    "    \n",
    "    return oneHotArray\n",
    "}\n",
    "\n",
    "// Get Numerical Features\n",
    "let numericalFeatures = dataFeatures.map{ row in numericalColumns.map{ row[$0] } }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "let trainPercentage:Float = 0.8\n",
    "let numTrainRecords = Int(ceil(Float(numRecords) * trainPercentage))\n",
    "let numTestRecords = numRecords - numTrainRecords\n",
    "\n",
    "func matrixTranspose<T>(_ matrix: [[T]]) -> [[T]] {\n",
    "    if matrix.isEmpty {return matrix}\n",
    "    var result = [[T]]()\n",
    "    for index in 0..<matrix.first!.count {\n",
    "        result.append(matrix.map{$0[index]})\n",
    "    }\n",
    "    return result\n",
    "}\n",
    "\n",
    "let xCategoricalAllTrain = matrixTranspose(Array(oneHotCategoricalFeatures[0..<numTrainRecords])).map{ Array($0.joined()) }\n",
    "let xCategoricalAllTest = matrixTranspose(Array(oneHotCategoricalFeatures[numTrainRecords...])).map{ Array($0.joined()) }\n",
    "let xNumericalAllTrain = Array(Array(numericalFeatures[0..<numTrainRecords]).joined())\n",
    "let xNumericalAllTest = Array(Array(numericalFeatures[numTrainRecords...]).joined())\n",
    "let yAllTrain = Array(Array(dataLabels[0..<numTrainRecords]).joined())\n",
    "let yAllTest = Array(Array(dataLabels[numTrainRecords...]).joined())\n",
    "\n",
    "let XCategoricalTrain = xCategoricalAllTrain.enumerated().map{ (offset, element) in \n",
    "    Tensor<Int32>(element).reshaped(to: TensorShape([numTrainRecords, embeddingSizes[offset]]))\n",
    "}\n",
    "let XCategoricalTest = xCategoricalAllTest.enumerated().map{ (offset, element) in \n",
    "    Tensor<Int32>(element).reshaped(to: TensorShape([numTestRecords, embeddingSizes[offset]]))\n",
    "}\n",
    "let XNumericalTrainDeNorm = Tensor<Float>(xNumericalAllTrain).reshaped(to: TensorShape([numTrainRecords, numNumericalFeatures]))\n",
    "let XNumericalTestDeNorm = Tensor<Float>(xNumericalAllTest).reshaped(to: TensorShape([numTestRecords, numNumericalFeatures]))\n",
    "let YTrain = Tensor<Float>(yAllTrain).reshaped(to: TensorShape([numTrainRecords, numLabels]))\n",
    "let YTest = Tensor<Float>(yAllTest).reshaped(to: TensorShape([numTestRecords, numLabels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.0137098,  14.197531,   9.523555, 0.53213036,  6.3311296,   64.47929,  4.1678762,  353.68396,\r\n",
      "    18.03163,  379.84735,  11.394517]] [[ 6.5076075,  25.258776,   6.534038, 0.11449408,  0.7311985,  29.000755,  2.1797554,  132.14561,\r\n",
      "    2.217345,  40.494495,   6.852825]]\r\n"
     ]
    }
   ],
   "source": [
    "let mean = XNumericalTrainDeNorm.mean(alongAxes: 0)\n",
    "let std = XNumericalTrainDeNorm.standardDeviation(alongAxes: 0)\n",
    "\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "let XNumericalTrain = (XNumericalTrainDeNorm - mean)/std\n",
    "let XNumericalTest = (XNumericalTestDeNorm - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shapes [405, 11] [405, 2] [405, 9] [405, 1]\r\n",
      "Testing shapes  [101, 11] [101, 2] [101, 9] [101, 1]\r\n"
     ]
    }
   ],
   "source": [
    "print(\"Training shapes \\(XNumericalTrain.shape) \\(XCategoricalTrain[0].shape) \\(XCategoricalTrain[1].shape) \\(YTrain.shape)\")\n",
    "print(\"Testing shapes  \\(XNumericalTest.shape) \\(XCategoricalTest[0].shape) \\(XCategoricalTest[1].shape) \\(YTest.shape)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HDJZCCgqohIC"
   },
   "outputs": [],
   "source": [
    "struct MultiInputs<N: Differentiable, C>: Differentiable {\n",
    "  var numerical: N\n",
    "  \n",
    "  @noDerivative\n",
    "  var categorical: C\n",
    "\n",
    "  @differentiable\n",
    "  init(numerical: N, categorical: C) {\n",
    "    self.numerical = numerical\n",
    "    self.categorical = categorical\n",
    "  }\n",
    "}\n",
    "\n",
    "struct RegressionModel: Module {\n",
    "    var numericalLayer = Dense<Float>(inputSize: 11, outputSize: 32, activation: relu)\n",
    "    var embedding1 = Embedding<Float>(vocabularySize: 2, embeddingSize: 2)\n",
    "    var embedding2 = Embedding<Float>(vocabularySize: 9, embeddingSize: 5)\n",
    "    var embeddingLayer = Dense<Float>(inputSize: (4 + 45), outputSize: 64, activation: relu)\n",
    "    var allInputConcatLayer = Dense<Float>(inputSize: (32 + 64), outputSize: 128, activation: relu)\n",
    "    var hiddenLayer = Dense<Float>(inputSize: 128, outputSize: 32, activation: relu)\n",
    "    var outputLayer = Dense<Float>(inputSize: 32, outputSize: 1)\n",
    "    \n",
    "    @differentiable\n",
    "    func callAsFunction(_ input: MultiInputs<[Tensor<Float>], [Tensor<Int32>]>) -> Tensor<Float> {\n",
    "        let numericalInput = numericalLayer(input.numerical[0])\n",
    "        let embeddingOutput1 = embedding1(input.categorical[0])\n",
    "        let embeddingOutput1Reshaped = embeddingOutput1.reshaped(to: \n",
    "            TensorShape([embeddingOutput1.shape[0], embeddingOutput1.shape[1] * embeddingOutput1.shape[2]]))\n",
    "        let embeddingOutput2 = embedding2(input.categorical[1])\n",
    "        let embeddingOutput2Reshaped = embeddingOutput2.reshaped(to: \n",
    "            TensorShape([embeddingOutput2.shape[0], embeddingOutput2.shape[1] * embeddingOutput2.shape[2]]))\n",
    "        let embeddingConcat = Tensor<Float>(concatenating: [embeddingOutput1Reshaped, embeddingOutput2Reshaped], alongAxis: 1)\n",
    "        let embeddingInput = embeddingLayer(embeddingConcat)\n",
    "        let allConcat = Tensor<Float>(concatenating: [numericalInput, embeddingInput], alongAxis: 1)\n",
    "        return allConcat.sequenced(through: allInputConcatLayer, hiddenLayer, outputLayer)\n",
    "    }\n",
    "}\n",
    "\n",
    "var model = RegressionModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JK0Vj7bSohIF"
   },
   "outputs": [],
   "source": [
    "let optimizer = RMSProp(for: model, learningRate: 0.001)\n",
    "Context.local.learningPhase = .training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gY8C7yHJohIH"
   },
   "outputs": [],
   "source": [
    "let epochCount = 500\n",
    "let batchSize = 32\n",
    "let numberOfBatch = Int(ceil(Double(numTrainRecords) / Double(batchSize)))\n",
    "let shuffle = true\n",
    "\n",
    "func mae(predictions: Tensor<Float>, truths: Tensor<Float>) -> Float {\n",
    "    return abs(Tensor<Float>(predictions - truths)).mean().scalarized()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "L9bU9HsdohIK",
    "outputId": "692b81c5-3286-4e7c-9246-eb56e6a3eaee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: MSE: 561.0152, MAE: 20.997587\n",
      "Epoch 2: MSE: 357.30536, MAE: 15.783238\n",
      "Epoch 3: MSE: 196.12015, MAE: 10.911716\n",
      "Epoch 4: MSE: 118.944565, MAE: 7.5713677\n",
      "Epoch 5: MSE: 91.62054, MAE: 6.2539334\n",
      "Epoch 6: MSE: 77.22692, MAE: 5.648963\n",
      "Epoch 7: MSE: 67.58952, MAE: 5.2488885\n",
      "Epoch 8: MSE: 59.54583, MAE: 4.878821\n",
      "Epoch 9: MSE: 52.289066, MAE: 4.5536394\n",
      "Epoch 10: MSE: 47.661724, MAE: 4.332935\n",
      "Epoch 11: MSE: 43.345066, MAE: 3.9419541\n",
      "Epoch 12: MSE: 40.67019, MAE: 3.8101451\n",
      "Epoch 13: MSE: 35.991726, MAE: 3.748586\n",
      "Epoch 14: MSE: 35.48568, MAE: 3.4018588\n",
      "Epoch 15: MSE: 33.962975, MAE: 3.3601305\n",
      "Epoch 16: MSE: 31.686687, MAE: 3.411875\n",
      "Epoch 17: MSE: 30.413136, MAE: 3.1732402\n",
      "Epoch 18: MSE: 28.818247, MAE: 3.0740914\n",
      "Epoch 19: MSE: 28.525036, MAE: 3.0059052\n",
      "Epoch 20: MSE: 26.9489, MAE: 3.0503619\n",
      "Epoch 21: MSE: 26.777122, MAE: 2.985069\n",
      "Epoch 22: MSE: 24.033762, MAE: 2.895381\n",
      "Epoch 23: MSE: 25.595734, MAE: 2.844287\n",
      "Epoch 24: MSE: 23.6858, MAE: 2.954912\n",
      "Epoch 25: MSE: 23.96878, MAE: 2.9035416\n",
      "Epoch 26: MSE: 23.744606, MAE: 2.7943838\n",
      "Epoch 27: MSE: 22.825819, MAE: 2.8011298\n",
      "Epoch 28: MSE: 21.491941, MAE: 2.7657433\n",
      "Epoch 29: MSE: 22.926252, MAE: 2.7155864\n",
      "Epoch 30: MSE: 22.07262, MAE: 2.7789018\n",
      "Epoch 31: MSE: 21.409525, MAE: 2.750791\n",
      "Epoch 32: MSE: 20.80089, MAE: 2.702648\n",
      "Epoch 33: MSE: 20.467255, MAE: 2.6614084\n",
      "Epoch 34: MSE: 20.771502, MAE: 2.6999257\n",
      "Epoch 35: MSE: 20.56195, MAE: 2.6197839\n",
      "Epoch 36: MSE: 19.563992, MAE: 2.6505017\n",
      "Epoch 37: MSE: 19.499807, MAE: 2.5813055\n",
      "Epoch 38: MSE: 19.409956, MAE: 2.6112409\n",
      "Epoch 39: MSE: 19.173409, MAE: 2.5768588\n",
      "Epoch 40: MSE: 18.479496, MAE: 2.52731\n",
      "Epoch 41: MSE: 19.593752, MAE: 2.551771\n",
      "Epoch 42: MSE: 17.78929, MAE: 2.5224211\n",
      "Epoch 43: MSE: 17.776438, MAE: 2.4923286\n",
      "Epoch 44: MSE: 18.034536, MAE: 2.5174294\n",
      "Epoch 45: MSE: 16.072397, MAE: 2.4340372\n",
      "Epoch 46: MSE: 17.998888, MAE: 2.4754865\n",
      "Epoch 47: MSE: 16.54562, MAE: 2.4055884\n",
      "Epoch 48: MSE: 16.222097, MAE: 2.3875601\n",
      "Epoch 49: MSE: 16.867678, MAE: 2.3963542\n",
      "Epoch 50: MSE: 16.088661, MAE: 2.3497915\n",
      "Epoch 51: MSE: 16.926722, MAE: 2.36139\n",
      "Epoch 52: MSE: 16.2239, MAE: 2.3428545\n",
      "Epoch 53: MSE: 14.439367, MAE: 2.3213239\n",
      "Epoch 54: MSE: 15.741858, MAE: 2.342702\n",
      "Epoch 55: MSE: 15.542268, MAE: 2.3233466\n",
      "Epoch 56: MSE: 14.913881, MAE: 2.2833624\n",
      "Epoch 57: MSE: 14.954637, MAE: 2.2808964\n",
      "Epoch 58: MSE: 15.978804, MAE: 2.2742414\n",
      "Epoch 59: MSE: 15.215317, MAE: 2.269563\n",
      "Epoch 60: MSE: 15.041062, MAE: 2.2389426\n",
      "Epoch 61: MSE: 14.715319, MAE: 2.2666817\n",
      "Epoch 62: MSE: 14.424166, MAE: 2.229488\n",
      "Epoch 63: MSE: 14.958012, MAE: 2.215505\n",
      "Epoch 64: MSE: 12.365568, MAE: 2.1851575\n",
      "Epoch 65: MSE: 13.818688, MAE: 2.193169\n",
      "Epoch 66: MSE: 13.777534, MAE: 2.2092195\n",
      "Epoch 67: MSE: 14.41992, MAE: 2.1826036\n",
      "Epoch 68: MSE: 13.110043, MAE: 2.1818445\n",
      "Epoch 69: MSE: 13.997077, MAE: 2.1565385\n",
      "Epoch 70: MSE: 12.508815, MAE: 2.1193826\n",
      "Epoch 71: MSE: 13.212611, MAE: 2.0897653\n",
      "Epoch 72: MSE: 12.461819, MAE: 2.084226\n",
      "Epoch 73: MSE: 12.590044, MAE: 2.1247938\n",
      "Epoch 74: MSE: 13.080546, MAE: 2.0801642\n",
      "Epoch 75: MSE: 13.293779, MAE: 2.079445\n",
      "Epoch 76: MSE: 11.203831, MAE: 2.055829\n",
      "Epoch 77: MSE: 12.44133, MAE: 2.0506196\n",
      "Epoch 78: MSE: 12.043497, MAE: 2.0504713\n",
      "Epoch 79: MSE: 11.938079, MAE: 2.027025\n",
      "Epoch 80: MSE: 11.0679865, MAE: 1.9953231\n",
      "Epoch 81: MSE: 11.952859, MAE: 2.043648\n",
      "Epoch 82: MSE: 11.122839, MAE: 2.0389333\n",
      "Epoch 83: MSE: 12.67385, MAE: 2.0245447\n",
      "Epoch 84: MSE: 10.675118, MAE: 2.0137289\n",
      "Epoch 85: MSE: 11.697908, MAE: 1.9860809\n",
      "Epoch 86: MSE: 9.887175, MAE: 1.9855115\n",
      "Epoch 87: MSE: 12.7288, MAE: 1.9845849\n",
      "Epoch 88: MSE: 10.560851, MAE: 1.9664478\n",
      "Epoch 89: MSE: 11.092097, MAE: 1.9495736\n",
      "Epoch 90: MSE: 10.352312, MAE: 1.9389533\n",
      "Epoch 91: MSE: 10.705239, MAE: 1.9535127\n",
      "Epoch 92: MSE: 10.478695, MAE: 1.9044425\n",
      "Epoch 93: MSE: 11.235868, MAE: 1.9125224\n",
      "Epoch 94: MSE: 10.103397, MAE: 1.9595125\n",
      "Epoch 95: MSE: 9.413387, MAE: 1.9029484\n",
      "Epoch 96: MSE: 10.301995, MAE: 1.8911903\n",
      "Epoch 97: MSE: 10.361189, MAE: 1.882148\n",
      "Epoch 98: MSE: 10.215578, MAE: 1.8382658\n",
      "Epoch 99: MSE: 9.50227, MAE: 1.8760947\n",
      "Epoch 100: MSE: 11.311706, MAE: 1.8778254\n",
      "Epoch 101: MSE: 9.821789, MAE: 1.836869\n",
      "Epoch 102: MSE: 9.421813, MAE: 1.8643848\n",
      "Epoch 103: MSE: 10.586594, MAE: 1.8636341\n",
      "Epoch 104: MSE: 9.24224, MAE: 1.8289056\n",
      "Epoch 105: MSE: 9.841246, MAE: 1.8312086\n",
      "Epoch 106: MSE: 9.244297, MAE: 1.8441848\n",
      "Epoch 107: MSE: 9.976208, MAE: 1.8239896\n",
      "Epoch 108: MSE: 9.073525, MAE: 1.8281121\n",
      "Epoch 109: MSE: 8.27233, MAE: 1.8530638\n",
      "Epoch 110: MSE: 8.524866, MAE: 1.8018187\n",
      "Epoch 111: MSE: 9.495347, MAE: 1.7964141\n",
      "Epoch 112: MSE: 9.2158375, MAE: 1.8173935\n",
      "Epoch 113: MSE: 9.328508, MAE: 1.7648183\n",
      "Epoch 114: MSE: 8.418039, MAE: 1.7536006\n",
      "Epoch 115: MSE: 8.820487, MAE: 1.7695277\n",
      "Epoch 116: MSE: 7.939764, MAE: 1.7640761\n",
      "Epoch 117: MSE: 9.355292, MAE: 1.7446829\n",
      "Epoch 118: MSE: 8.5328665, MAE: 1.7824048\n",
      "Epoch 119: MSE: 7.721233, MAE: 1.7343285\n",
      "Epoch 120: MSE: 9.05969, MAE: 1.714876\n",
      "Epoch 121: MSE: 8.325196, MAE: 1.7146853\n",
      "Epoch 122: MSE: 7.522482, MAE: 1.6804404\n",
      "Epoch 123: MSE: 6.9788747, MAE: 1.7201766\n",
      "Epoch 124: MSE: 7.849011, MAE: 1.7483733\n",
      "Epoch 125: MSE: 7.7712994, MAE: 1.690443\n",
      "Epoch 126: MSE: 7.7889886, MAE: 1.7043617\n",
      "Epoch 127: MSE: 8.293128, MAE: 1.6624622\n",
      "Epoch 128: MSE: 7.995934, MAE: 1.6428808\n",
      "Epoch 129: MSE: 7.456864, MAE: 1.7197607\n",
      "Epoch 130: MSE: 8.512974, MAE: 1.7143873\n",
      "Epoch 131: MSE: 8.281828, MAE: 1.6287335\n",
      "Epoch 132: MSE: 7.8613873, MAE: 1.6674658\n",
      "Epoch 133: MSE: 8.3884535, MAE: 1.6700066\n",
      "Epoch 134: MSE: 7.739718, MAE: 1.6531316\n",
      "Epoch 135: MSE: 7.8481426, MAE: 1.6368527\n",
      "Epoch 136: MSE: 7.3884635, MAE: 1.6441157\n",
      "Epoch 137: MSE: 8.0894785, MAE: 1.645738\n",
      "Epoch 138: MSE: 6.9392843, MAE: 1.6213214\n",
      "Epoch 139: MSE: 7.8905034, MAE: 1.6490611\n",
      "Epoch 140: MSE: 6.404505, MAE: 1.6036681\n",
      "Epoch 141: MSE: 8.267198, MAE: 1.7015756\n",
      "Epoch 142: MSE: 6.831132, MAE: 1.6092427\n",
      "Epoch 143: MSE: 7.1544666, MAE: 1.6328466\n",
      "Epoch 144: MSE: 7.0882287, MAE: 1.6579329\n",
      "Epoch 145: MSE: 6.8338113, MAE: 1.6263847\n",
      "Epoch 146: MSE: 7.4232283, MAE: 1.6292043\n",
      "Epoch 147: MSE: 7.863029, MAE: 1.5571791\n",
      "Epoch 148: MSE: 6.3523226, MAE: 1.5617077\n",
      "Epoch 149: MSE: 7.2325363, MAE: 1.5992076\n",
      "Epoch 150: MSE: 6.2996197, MAE: 1.600813\n",
      "Epoch 151: MSE: 6.9338098, MAE: 1.6648813\n",
      "Epoch 152: MSE: 6.6607165, MAE: 1.6272005\n",
      "Epoch 153: MSE: 7.590527, MAE: 1.5828446\n",
      "Epoch 154: MSE: 6.706371, MAE: 1.5581262\n",
      "Epoch 155: MSE: 7.0865855, MAE: 1.6018205\n",
      "Epoch 156: MSE: 6.9798045, MAE: 1.6100186\n",
      "Epoch 157: MSE: 6.344296, MAE: 1.5928218\n",
      "Epoch 158: MSE: 7.2989473, MAE: 1.5634944\n",
      "Epoch 159: MSE: 6.3190584, MAE: 1.537541\n",
      "Epoch 160: MSE: 7.2432427, MAE: 1.5733236\n",
      "Epoch 161: MSE: 5.6909885, MAE: 1.5150827\n",
      "Epoch 162: MSE: 7.297242, MAE: 1.5772458\n",
      "Epoch 163: MSE: 6.405134, MAE: 1.4892272\n",
      "Epoch 164: MSE: 6.7747912, MAE: 1.5595316\n",
      "Epoch 165: MSE: 5.554331, MAE: 1.5763164\n",
      "Epoch 166: MSE: 6.3914647, MAE: 1.5486796\n",
      "Epoch 167: MSE: 6.4525886, MAE: 1.5376146\n",
      "Epoch 168: MSE: 6.582594, MAE: 1.5386859\n",
      "Epoch 169: MSE: 5.5341434, MAE: 1.5148321\n",
      "Epoch 170: MSE: 6.462173, MAE: 1.554174\n",
      "Epoch 171: MSE: 6.025256, MAE: 1.5822123\n",
      "Epoch 172: MSE: 6.602682, MAE: 1.5503905\n",
      "Epoch 173: MSE: 6.1304812, MAE: 1.4861939\n",
      "Epoch 174: MSE: 6.249314, MAE: 1.4942693\n",
      "Epoch 175: MSE: 6.339299, MAE: 1.5296566\n",
      "Epoch 176: MSE: 5.158087, MAE: 1.5466632\n",
      "Epoch 177: MSE: 6.1187716, MAE: 1.5443149\n",
      "Epoch 178: MSE: 5.953577, MAE: 1.5133746\n",
      "Epoch 179: MSE: 5.2965097, MAE: 1.4749418\n",
      "Epoch 180: MSE: 5.645318, MAE: 1.5580966\n",
      "Epoch 181: MSE: 6.574021, MAE: 1.4960716\n",
      "Epoch 182: MSE: 5.6126275, MAE: 1.517826\n",
      "Epoch 183: MSE: 5.740347, MAE: 1.4990177\n",
      "Epoch 184: MSE: 6.0939403, MAE: 1.4742572\n",
      "Epoch 185: MSE: 5.456536, MAE: 1.4777375\n",
      "Epoch 186: MSE: 5.5321417, MAE: 1.4804409\n",
      "Epoch 187: MSE: 4.9895296, MAE: 1.5112512\n",
      "Epoch 188: MSE: 6.3080106, MAE: 1.5147164\n",
      "Epoch 189: MSE: 5.3798246, MAE: 1.4393749\n",
      "Epoch 190: MSE: 5.7970867, MAE: 1.4546827\n",
      "Epoch 191: MSE: 5.2763643, MAE: 1.4501945\n",
      "Epoch 192: MSE: 4.8267646, MAE: 1.4830668\n",
      "Epoch 193: MSE: 5.9517584, MAE: 1.5707694\n",
      "Epoch 194: MSE: 5.646589, MAE: 1.4986002\n",
      "Epoch 195: MSE: 5.3171687, MAE: 1.4414712\n",
      "Epoch 196: MSE: 5.21526, MAE: 1.4496995\n",
      "Epoch 197: MSE: 5.5362234, MAE: 1.4929054\n",
      "Epoch 198: MSE: 4.956132, MAE: 1.4106469\n",
      "Epoch 199: MSE: 4.628159, MAE: 1.5479382\n",
      "Epoch 200: MSE: 4.7427692, MAE: 1.5721499\n",
      "Epoch 201: MSE: 5.9145503, MAE: 1.499504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202: MSE: 5.8218985, MAE: 1.4854475\n",
      "Epoch 203: MSE: 4.2392707, MAE: 1.3973844\n",
      "Epoch 204: MSE: 6.0961485, MAE: 1.5515734\n",
      "Epoch 205: MSE: 5.300884, MAE: 1.4435271\n",
      "Epoch 206: MSE: 4.7900896, MAE: 1.4255292\n",
      "Epoch 207: MSE: 4.626521, MAE: 1.4776471\n",
      "Epoch 208: MSE: 5.7123137, MAE: 1.4614472\n",
      "Epoch 209: MSE: 5.2897954, MAE: 1.4243444\n",
      "Epoch 210: MSE: 5.2005415, MAE: 1.4611669\n",
      "Epoch 211: MSE: 4.5226965, MAE: 1.3935704\n",
      "Epoch 212: MSE: 6.136378, MAE: 1.5076531\n",
      "Epoch 213: MSE: 4.2014503, MAE: 1.3140907\n",
      "Epoch 214: MSE: 5.2831087, MAE: 1.5371026\n",
      "Epoch 215: MSE: 4.7702336, MAE: 1.4558277\n",
      "Epoch 216: MSE: 4.3522005, MAE: 1.3818283\n",
      "Epoch 217: MSE: 4.4555917, MAE: 1.4910088\n",
      "Epoch 218: MSE: 4.4346466, MAE: 1.4388064\n",
      "Epoch 219: MSE: 5.9545927, MAE: 1.526848\n",
      "Epoch 220: MSE: 4.3214087, MAE: 1.3611051\n",
      "Epoch 221: MSE: 5.382268, MAE: 1.5569413\n",
      "Epoch 222: MSE: 4.1144643, MAE: 1.3599629\n",
      "Epoch 223: MSE: 4.909648, MAE: 1.462206\n",
      "Epoch 224: MSE: 4.1703167, MAE: 1.3853177\n",
      "Epoch 225: MSE: 5.649729, MAE: 1.4806412\n",
      "Epoch 226: MSE: 4.318535, MAE: 1.3214169\n",
      "Epoch 227: MSE: 5.136567, MAE: 1.4845321\n",
      "Epoch 228: MSE: 4.354394, MAE: 1.3738711\n",
      "Epoch 229: MSE: 5.414149, MAE: 1.476256\n",
      "Epoch 230: MSE: 4.3635416, MAE: 1.3308289\n",
      "Epoch 231: MSE: 4.602031, MAE: 1.3241998\n",
      "Epoch 232: MSE: 5.084985, MAE: 1.4880893\n",
      "Epoch 233: MSE: 4.123787, MAE: 1.3308666\n",
      "Epoch 234: MSE: 3.8992, MAE: 1.4320325\n",
      "Epoch 235: MSE: 4.883593, MAE: 1.4467485\n",
      "Epoch 236: MSE: 3.8192358, MAE: 1.3675843\n",
      "Epoch 237: MSE: 4.779061, MAE: 1.5454837\n",
      "Epoch 238: MSE: 4.4520645, MAE: 1.3681325\n",
      "Epoch 239: MSE: 4.7576113, MAE: 1.4686835\n",
      "Epoch 240: MSE: 4.458507, MAE: 1.3704674\n",
      "Epoch 241: MSE: 4.839747, MAE: 1.4430652\n",
      "Epoch 242: MSE: 3.8178058, MAE: 1.332066\n",
      "Epoch 243: MSE: 4.1920657, MAE: 1.3665403\n",
      "Epoch 244: MSE: 4.6157627, MAE: 1.5687727\n",
      "Epoch 245: MSE: 4.376622, MAE: 1.3709481\n",
      "Epoch 246: MSE: 3.4808104, MAE: 1.3314191\n",
      "Epoch 247: MSE: 4.2077456, MAE: 1.4885242\n",
      "Epoch 248: MSE: 4.3273525, MAE: 1.4132215\n",
      "Epoch 249: MSE: 3.9259229, MAE: 1.3224899\n",
      "Epoch 250: MSE: 5.3348393, MAE: 1.4715964\n",
      "Epoch 251: MSE: 3.453144, MAE: 1.2359817\n",
      "Epoch 252: MSE: 4.217165, MAE: 1.4063983\n",
      "Epoch 253: MSE: 3.9115434, MAE: 1.3778529\n",
      "Epoch 254: MSE: 3.2136714, MAE: 1.4059614\n",
      "Epoch 255: MSE: 3.738389, MAE: 1.4593728\n",
      "Epoch 256: MSE: 5.4746776, MAE: 1.4789613\n",
      "Epoch 257: MSE: 3.7604303, MAE: 1.3159428\n",
      "Epoch 258: MSE: 3.8536558, MAE: 1.2876492\n",
      "Epoch 259: MSE: 4.229175, MAE: 1.4380475\n",
      "Epoch 260: MSE: 3.9932492, MAE: 1.3368677\n",
      "Epoch 261: MSE: 3.4765718, MAE: 1.3582153\n",
      "Epoch 262: MSE: 3.7493033, MAE: 1.4834136\n",
      "Epoch 263: MSE: 4.753416, MAE: 1.4231778\n",
      "Epoch 264: MSE: 3.9641016, MAE: 1.3114429\n",
      "Epoch 265: MSE: 4.328548, MAE: 1.4147403\n",
      "Epoch 266: MSE: 3.3673582, MAE: 1.3050317\n",
      "Epoch 267: MSE: 3.8350809, MAE: 1.4557471\n",
      "Epoch 268: MSE: 4.238225, MAE: 1.3754393\n",
      "Epoch 269: MSE: 4.7775717, MAE: 1.349022\n",
      "Epoch 270: MSE: 3.34518, MAE: 1.2384171\n",
      "Epoch 271: MSE: 4.013385, MAE: 1.4109318\n",
      "Epoch 272: MSE: 3.721335, MAE: 1.3521268\n",
      "Epoch 273: MSE: 3.6717184, MAE: 1.4285235\n",
      "Epoch 274: MSE: 3.3568006, MAE: 1.3501396\n",
      "Epoch 275: MSE: 4.3691096, MAE: 1.4684274\n",
      "Epoch 276: MSE: 4.0105696, MAE: 1.3079991\n",
      "Epoch 277: MSE: 4.202369, MAE: 1.3223877\n",
      "Epoch 278: MSE: 3.7419243, MAE: 1.3150027\n",
      "Epoch 279: MSE: 3.9557762, MAE: 1.4234151\n",
      "Epoch 280: MSE: 3.925892, MAE: 1.3539786\n",
      "Epoch 281: MSE: 4.053844, MAE: 1.3392758\n",
      "Epoch 282: MSE: 3.1663654, MAE: 1.1719109\n",
      "Epoch 283: MSE: 4.8011622, MAE: 1.4129347\n",
      "Epoch 284: MSE: 3.5090954, MAE: 1.2961941\n",
      "Epoch 285: MSE: 3.9875562, MAE: 1.2954344\n",
      "Epoch 286: MSE: 3.7022824, MAE: 1.3746699\n",
      "Epoch 287: MSE: 3.783632, MAE: 1.2988031\n",
      "Epoch 288: MSE: 3.4632478, MAE: 1.3140081\n",
      "Epoch 289: MSE: 3.8437386, MAE: 1.3915505\n",
      "Epoch 290: MSE: 3.5950801, MAE: 1.308193\n",
      "Epoch 291: MSE: 3.4570928, MAE: 1.3317525\n",
      "Epoch 292: MSE: 4.0160565, MAE: 1.3575929\n",
      "Epoch 293: MSE: 3.854797, MAE: 1.3872511\n",
      "Epoch 294: MSE: 3.3314872, MAE: 1.2139467\n",
      "Epoch 295: MSE: 3.3902566, MAE: 1.4839898\n",
      "Epoch 296: MSE: 3.6852314, MAE: 1.3267462\n",
      "Epoch 297: MSE: 3.836191, MAE: 1.3745848\n",
      "Epoch 298: MSE: 3.8299525, MAE: 1.2156737\n",
      "Epoch 299: MSE: 3.3198352, MAE: 1.3826267\n",
      "Epoch 300: MSE: 3.0863168, MAE: 1.3186599\n",
      "Epoch 301: MSE: 3.1985354, MAE: 1.2633573\n",
      "Epoch 302: MSE: 4.166431, MAE: 1.4321702\n",
      "Epoch 303: MSE: 3.972698, MAE: 1.3470974\n",
      "Epoch 304: MSE: 3.37412, MAE: 1.2837495\n",
      "Epoch 305: MSE: 3.0245256, MAE: 1.2791032\n",
      "Epoch 306: MSE: 3.9887898, MAE: 1.4245874\n",
      "Epoch 307: MSE: 3.6593747, MAE: 1.3098171\n",
      "Epoch 308: MSE: 4.219243, MAE: 1.2728595\n",
      "Epoch 309: MSE: 3.1083722, MAE: 1.1995115\n",
      "Epoch 310: MSE: 4.010935, MAE: 1.2557431\n",
      "Epoch 311: MSE: 2.985381, MAE: 1.1609671\n",
      "Epoch 312: MSE: 4.259045, MAE: 1.4477112\n",
      "Epoch 313: MSE: 3.6911016, MAE: 1.2212224\n",
      "Epoch 314: MSE: 3.264894, MAE: 1.271585\n",
      "Epoch 315: MSE: 2.722776, MAE: 1.2211081\n",
      "Epoch 316: MSE: 4.6350203, MAE: 1.4491718\n",
      "Epoch 317: MSE: 3.0069501, MAE: 1.2854253\n",
      "Epoch 318: MSE: 3.523158, MAE: 1.221828\n",
      "Epoch 319: MSE: 3.5994976, MAE: 1.4233826\n",
      "Epoch 320: MSE: 3.3561428, MAE: 1.271159\n",
      "Epoch 321: MSE: 4.0604625, MAE: 1.3439605\n",
      "Epoch 322: MSE: 3.5685034, MAE: 1.2983648\n",
      "Epoch 323: MSE: 2.696594, MAE: 1.1862088\n",
      "Epoch 324: MSE: 3.9382155, MAE: 1.4740808\n",
      "Epoch 325: MSE: 3.8069625, MAE: 1.3281949\n",
      "Epoch 326: MSE: 3.1822712, MAE: 1.2543734\n",
      "Epoch 327: MSE: 2.4936671, MAE: 1.165056\n",
      "Epoch 328: MSE: 4.51827, MAE: 1.4422126\n",
      "Epoch 329: MSE: 2.7747273, MAE: 1.1508219\n",
      "Epoch 330: MSE: 3.3165221, MAE: 1.4024734\n",
      "Epoch 331: MSE: 3.5091443, MAE: 1.241962\n",
      "Epoch 332: MSE: 3.442037, MAE: 1.320399\n",
      "Epoch 333: MSE: 3.3460188, MAE: 1.2247175\n",
      "Epoch 334: MSE: 3.0599897, MAE: 1.212023\n",
      "Epoch 335: MSE: 3.1318412, MAE: 1.3961818\n",
      "Epoch 336: MSE: 4.4736624, MAE: 1.2204515\n",
      "Epoch 337: MSE: 2.8982635, MAE: 1.1599144\n",
      "Epoch 338: MSE: 3.202882, MAE: 1.35172\n",
      "Epoch 339: MSE: 3.3178236, MAE: 1.2540739\n",
      "Epoch 340: MSE: 3.8785129, MAE: 1.3819498\n",
      "Epoch 341: MSE: 3.1513827, MAE: 1.3062155\n",
      "Epoch 342: MSE: 3.4252768, MAE: 1.2760171\n",
      "Epoch 343: MSE: 2.8248432, MAE: 1.2548218\n",
      "Epoch 344: MSE: 2.819073, MAE: 1.3493131\n",
      "Epoch 345: MSE: 3.9567628, MAE: 1.3774687\n",
      "Epoch 346: MSE: 2.765165, MAE: 1.2522172\n",
      "Epoch 347: MSE: 3.3300884, MAE: 1.2625955\n",
      "Epoch 348: MSE: 3.291316, MAE: 1.386126\n",
      "Epoch 349: MSE: 3.7639809, MAE: 1.2809408\n",
      "Epoch 350: MSE: 2.701759, MAE: 1.2332318\n",
      "Epoch 351: MSE: 2.9803693, MAE: 1.3532726\n",
      "Epoch 352: MSE: 3.8859096, MAE: 1.2544073\n",
      "Epoch 353: MSE: 2.4855132, MAE: 1.2623044\n",
      "Epoch 354: MSE: 4.012765, MAE: 1.3980463\n",
      "Epoch 355: MSE: 3.2068787, MAE: 1.1951259\n",
      "Epoch 356: MSE: 2.963319, MAE: 1.2886577\n",
      "Epoch 357: MSE: 3.145758, MAE: 1.2245042\n",
      "Epoch 358: MSE: 2.9060602, MAE: 1.299268\n",
      "Epoch 359: MSE: 3.3312693, MAE: 1.4365838\n",
      "Epoch 360: MSE: 3.4040804, MAE: 1.227215\n",
      "Epoch 361: MSE: 3.9128642, MAE: 1.3015015\n",
      "Epoch 362: MSE: 2.669097, MAE: 1.1011915\n",
      "Epoch 363: MSE: 2.8845096, MAE: 1.3579237\n",
      "Epoch 364: MSE: 3.2734714, MAE: 1.241723\n",
      "Epoch 365: MSE: 2.7108383, MAE: 1.29632\n",
      "Epoch 366: MSE: 4.494166, MAE: 1.2998606\n",
      "Epoch 367: MSE: 2.6148276, MAE: 1.1710643\n",
      "Epoch 368: MSE: 3.8854244, MAE: 1.2389001\n",
      "Epoch 369: MSE: 2.8064864, MAE: 1.2979361\n",
      "Epoch 370: MSE: 3.4854014, MAE: 1.2195896\n",
      "Epoch 371: MSE: 2.7389445, MAE: 1.1588022\n",
      "Epoch 372: MSE: 2.9291453, MAE: 1.3008411\n",
      "Epoch 373: MSE: 4.0545664, MAE: 1.4597659\n",
      "Epoch 374: MSE: 2.603905, MAE: 1.1022651\n",
      "Epoch 375: MSE: 2.8082151, MAE: 1.2846755\n",
      "Epoch 376: MSE: 3.3788264, MAE: 1.3559222\n",
      "Epoch 377: MSE: 3.3740587, MAE: 1.3575623\n",
      "Epoch 378: MSE: 3.254124, MAE: 1.2463775\n",
      "Epoch 379: MSE: 2.5425344, MAE: 1.2281123\n",
      "Epoch 380: MSE: 4.3518786, MAE: 1.3804626\n",
      "Epoch 381: MSE: 2.2188258, MAE: 1.0334721\n",
      "Epoch 382: MSE: 3.0436106, MAE: 1.3969922\n",
      "Epoch 383: MSE: 3.1913793, MAE: 1.3840251\n",
      "Epoch 384: MSE: 3.6296628, MAE: 1.3220251\n",
      "Epoch 385: MSE: 2.5924437, MAE: 1.1481904\n",
      "Epoch 386: MSE: 3.1624727, MAE: 1.3930327\n",
      "Epoch 387: MSE: 2.962138, MAE: 1.1981791\n",
      "Epoch 388: MSE: 2.9806929, MAE: 1.330956\n",
      "Epoch 389: MSE: 3.2787552, MAE: 1.2481418\n",
      "Epoch 390: MSE: 2.5460854, MAE: 1.1762811\n",
      "Epoch 391: MSE: 3.6385553, MAE: 1.3664963\n",
      "Epoch 392: MSE: 2.9272792, MAE: 1.1909064\n",
      "Epoch 393: MSE: 2.5525513, MAE: 1.3359011\n",
      "Epoch 394: MSE: 3.5141382, MAE: 1.1198474\n",
      "Epoch 395: MSE: 3.150463, MAE: 1.4121385\n",
      "Epoch 396: MSE: 2.4987211, MAE: 1.2001044\n",
      "Epoch 397: MSE: 2.4296622, MAE: 1.3015639\n",
      "Epoch 398: MSE: 4.565964, MAE: 1.4258031\n",
      "Epoch 399: MSE: 2.898837, MAE: 1.144869\n",
      "Epoch 400: MSE: 2.8552134, MAE: 1.197752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401: MSE: 2.610495, MAE: 1.1128999\n",
      "Epoch 402: MSE: 2.8085387, MAE: 1.1667833\n",
      "Epoch 403: MSE: 3.5009725, MAE: 1.4362079\n",
      "Epoch 404: MSE: 2.7984424, MAE: 1.1148496\n",
      "Epoch 405: MSE: 2.6698468, MAE: 1.3681138\n",
      "Epoch 406: MSE: 3.67716, MAE: 1.2124313\n",
      "Epoch 407: MSE: 3.0693297, MAE: 1.2827505\n",
      "Epoch 408: MSE: 3.046108, MAE: 1.2541758\n",
      "Epoch 409: MSE: 3.087418, MAE: 1.2654309\n",
      "Epoch 410: MSE: 2.515476, MAE: 1.3148875\n",
      "Epoch 411: MSE: 2.976318, MAE: 1.2386342\n",
      "Epoch 412: MSE: 2.9019837, MAE: 1.3012873\n",
      "Epoch 413: MSE: 2.7301676, MAE: 1.2721019\n",
      "Epoch 414: MSE: 3.8036978, MAE: 1.2635882\n",
      "Epoch 415: MSE: 2.3211625, MAE: 1.1131544\n",
      "Epoch 416: MSE: 2.4859173, MAE: 1.2634228\n",
      "Epoch 417: MSE: 2.96648, MAE: 1.3307147\n",
      "Epoch 418: MSE: 2.7112005, MAE: 1.33182\n",
      "Epoch 419: MSE: 3.9461405, MAE: 1.1985836\n",
      "Epoch 420: MSE: 2.5999777, MAE: 1.1493604\n",
      "Epoch 421: MSE: 2.1765685, MAE: 1.1486284\n",
      "Epoch 422: MSE: 3.0443406, MAE: 1.3160597\n",
      "Epoch 423: MSE: 3.22652, MAE: 1.4282454\n",
      "Epoch 424: MSE: 3.2868147, MAE: 1.2721475\n",
      "Epoch 425: MSE: 2.5939786, MAE: 1.2143372\n",
      "Epoch 426: MSE: 3.0915327, MAE: 1.3936541\n",
      "Epoch 427: MSE: 2.5531375, MAE: 1.2139373\n",
      "Epoch 428: MSE: 3.4815295, MAE: 1.2208809\n",
      "Epoch 429: MSE: 2.3184009, MAE: 1.0794042\n",
      "Epoch 430: MSE: 2.5051742, MAE: 1.2532557\n",
      "Epoch 431: MSE: 3.77079, MAE: 1.1477846\n",
      "Epoch 432: MSE: 2.129787, MAE: 1.1187313\n",
      "Epoch 433: MSE: 3.1627047, MAE: 1.370346\n",
      "Epoch 434: MSE: 3.1997592, MAE: 1.2624917\n",
      "Epoch 435: MSE: 3.2734175, MAE: 1.2409731\n",
      "Epoch 436: MSE: 2.4155264, MAE: 1.165788\n",
      "Epoch 437: MSE: 2.7649763, MAE: 1.2514141\n",
      "Epoch 438: MSE: 2.5261788, MAE: 1.2808362\n",
      "Epoch 439: MSE: 2.769895, MAE: 1.4149953\n",
      "Epoch 440: MSE: 3.5063937, MAE: 1.0888991\n",
      "Epoch 441: MSE: 2.7618432, MAE: 1.1826302\n",
      "Epoch 442: MSE: 2.441712, MAE: 1.1914674\n",
      "Epoch 443: MSE: 2.7499578, MAE: 1.3762666\n",
      "Epoch 444: MSE: 3.0386586, MAE: 1.2805787\n",
      "Epoch 445: MSE: 2.4929538, MAE: 1.1690611\n",
      "Epoch 446: MSE: 4.0429635, MAE: 1.258646\n",
      "Epoch 447: MSE: 2.0398655, MAE: 0.99029446\n",
      "Epoch 448: MSE: 2.1545045, MAE: 1.2051665\n",
      "Epoch 449: MSE: 3.1714475, MAE: 1.3722248\n",
      "Epoch 450: MSE: 3.4675512, MAE: 1.3120532\n",
      "Epoch 451: MSE: 2.0828774, MAE: 1.0497327\n",
      "Epoch 452: MSE: 3.1429126, MAE: 1.2062961\n",
      "Epoch 453: MSE: 2.8113894, MAE: 1.1643962\n",
      "Epoch 454: MSE: 2.9914129, MAE: 1.2724216\n",
      "Epoch 455: MSE: 2.3496792, MAE: 1.1938304\n",
      "Epoch 456: MSE: 2.534266, MAE: 1.3368818\n",
      "Epoch 457: MSE: 2.576991, MAE: 1.2411311\n",
      "Epoch 458: MSE: 3.2307215, MAE: 1.3705785\n",
      "Epoch 459: MSE: 2.418234, MAE: 1.087802\n",
      "Epoch 460: MSE: 3.9225683, MAE: 1.3305678\n",
      "Epoch 461: MSE: 1.958496, MAE: 0.9750623\n",
      "Epoch 462: MSE: 3.4844682, MAE: 1.2985502\n",
      "Epoch 463: MSE: 1.9226767, MAE: 0.96512043\n",
      "Epoch 464: MSE: 3.4152637, MAE: 1.4510405\n",
      "Epoch 465: MSE: 2.621647, MAE: 1.0792749\n",
      "Epoch 466: MSE: 2.835882, MAE: 1.3004196\n",
      "Epoch 467: MSE: 2.1223822, MAE: 1.0739359\n",
      "Epoch 468: MSE: 3.381733, MAE: 1.3610008\n",
      "Epoch 469: MSE: 2.3803782, MAE: 1.0740035\n",
      "Epoch 470: MSE: 3.4007268, MAE: 1.3216535\n",
      "Epoch 471: MSE: 2.3779151, MAE: 1.1125013\n",
      "Epoch 472: MSE: 3.1435835, MAE: 1.3013846\n",
      "Epoch 473: MSE: 2.68447, MAE: 1.1883782\n",
      "Epoch 474: MSE: 2.32037, MAE: 1.2236664\n",
      "Epoch 475: MSE: 2.2445235, MAE: 1.1662943\n",
      "Epoch 476: MSE: 2.2358935, MAE: 1.3864136\n",
      "Epoch 477: MSE: 2.8727276, MAE: 1.3093883\n",
      "Epoch 478: MSE: 3.0135117, MAE: 1.2318356\n",
      "Epoch 479: MSE: 2.980721, MAE: 1.1141055\n",
      "Epoch 480: MSE: 2.4117162, MAE: 1.1749486\n",
      "Epoch 481: MSE: 2.6618934, MAE: 1.2974523\n",
      "Epoch 482: MSE: 2.7661934, MAE: 1.2233049\n",
      "Epoch 483: MSE: 3.1492178, MAE: 1.204683\n",
      "Epoch 484: MSE: 2.5355084, MAE: 1.1670991\n",
      "Epoch 485: MSE: 2.7093623, MAE: 1.3300354\n",
      "Epoch 486: MSE: 2.3291373, MAE: 1.1341698\n",
      "Epoch 487: MSE: 3.1095026, MAE: 1.1777532\n",
      "Epoch 488: MSE: 2.5956817, MAE: 1.2357466\n",
      "Epoch 489: MSE: 2.1291716, MAE: 1.2599822\n",
      "Epoch 490: MSE: 3.377796, MAE: 1.4063239\n",
      "Epoch 491: MSE: 2.5272837, MAE: 1.1056123\n",
      "Epoch 492: MSE: 2.7965434, MAE: 1.1242824\n",
      "Epoch 493: MSE: 2.5631168, MAE: 1.1032145\n",
      "Epoch 494: MSE: 2.6980667, MAE: 1.259416\n",
      "Epoch 495: MSE: 2.1056657, MAE: 1.1983272\n",
      "Epoch 496: MSE: 3.2226126, MAE: 1.3269928\n",
      "Epoch 497: MSE: 2.4003272, MAE: 1.0919349\n",
      "Epoch 498: MSE: 2.4929419, MAE: 1.3142269\n",
      "Epoch 499: MSE: 3.4417918, MAE: 1.2673119\n",
      "Epoch 500: MSE: 2.4350934, MAE: 1.0745233\n"
     ]
    }
   ],
   "source": [
    "for epoch in 1...epochCount {\n",
    "    var epochLoss: Float = 0\n",
    "    var epochMAE: Float = 0\n",
    "    var batchCount: Int = 0\n",
    "    var batchArray = Array(repeating: false, count: numberOfBatch)\n",
    "    for batch in 0..<numberOfBatch {\n",
    "        var r = batch\n",
    "        if shuffle {\n",
    "            while true {\n",
    "                r = Int.random(in: 0..<numberOfBatch)\n",
    "                if !batchArray[r] {\n",
    "                    batchArray[r] = true\n",
    "                    break\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        let batchStart = r * batchSize\n",
    "        let batchEnd = min(numTrainRecords, batchStart + batchSize)\n",
    "        let (loss, grad) = model.valueWithGradient { (model: RegressionModel) -> Tensor<Float> in\n",
    "            let multiInput = MultiInputs(numerical: [XNumericalTrain[batchStart..<batchEnd]],\n",
    "                                         categorical: [XCategoricalTrain[0][batchStart..<batchEnd],\n",
    "                                                       XCategoricalTrain[1][batchStart..<batchEnd]])\n",
    "            let logits = model(multiInput)\n",
    "            return meanSquaredError(predicted: logits, expected: YTrain[batchStart..<batchEnd])\n",
    "        }\n",
    "        optimizer.update(&model, along: grad)\n",
    "        \n",
    "        let multiInput = MultiInputs(numerical: [XNumericalTrain[batchStart..<batchEnd]],\n",
    "                                     categorical: [XCategoricalTrain[0][batchStart..<batchEnd],\n",
    "                                                   XCategoricalTrain[1][batchStart..<batchEnd]])\n",
    "        let logits = model(multiInput)\n",
    "        epochMAE += mae(predictions: logits, truths: YTrain[batchStart..<batchEnd])\n",
    "        epochLoss += loss.scalarized()\n",
    "        batchCount += 1\n",
    "    }\n",
    "    epochMAE /= Float(batchCount)\n",
    "    epochLoss /= Float(batchCount)\n",
    "\n",
    "    print(\"Epoch \\(epoch): MSE: \\(epochLoss), MAE: \\(epochMAE)\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.33494344, MAE: 0.040072046\r\n"
     ]
    }
   ],
   "source": [
    "Context.local.learningPhase = .inference\n",
    "\n",
    "let multiInputTest = MultiInputs(numerical: [XNumericalTest],\n",
    "                                 categorical: [XCategoricalTest[0],\n",
    "                                               XCategoricalTest[1]])\n",
    "\n",
    "let prediction = model(multiInputTest)\n",
    "\n",
    "let predictionMse = meanSquaredError(predicted: prediction, expected: YTest).scalarized()/Float(numTestRecords)\n",
    "let predictionMae = mae(predictions: prediction, truths: YTest)/Float(numTestRecords)\n",
    "\n",
    "print(\"MSE: \\(predictionMse), MAE: \\(predictionMae)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fkf29HLlohIP"
   },
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "// print(model.layer1.weight.shape, model.layer2.weight.shape, model.layer3.weight.shape)\n",
    "// print(model.layer1.bias.shape, model.layer2.bias.shape, model.layer3.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "// let coremlModel = Model(version: 4,\n",
    "//                         shortDescription: \"Regression\",\n",
    "//                         author: \"Jacopo Mangiavacchi\",\n",
    "//                         license: \"MIT\",\n",
    "//                         userDefined: [\"SwiftCoremltoolsVersion\" : \"0.0.3\"]) {\n",
    "//     Input(name: \"input\", shape: [13])\n",
    "//     Output(name: \"output\", shape: [1])\n",
    "//     NeuralNetwork {\n",
    "//         InnerProduct(name: \"dense1\",\n",
    "//                      input: [\"input\"],\n",
    "//                      output: [\"outDense1\"],\n",
    "//                      weight: model.layer1.weight.transposed().flattened().scalars,\n",
    "//                      bias: model.layer1.bias.flattened().scalars,\n",
    "//                      inputChannels: 13,\n",
    "//                      outputChannels: 64)\n",
    "//         ReLu(name: \"Relu1\",\n",
    "//              input: [\"outDense1\"],\n",
    "//              output: [\"outRelu1\"])\n",
    "//         InnerProduct(name: \"dense2\",\n",
    "//                      input: [\"outRelu1\"],\n",
    "//                      output: [\"outDense2\"],\n",
    "//                      weight: model.layer2.weight.transposed().flattened().scalars,\n",
    "//                      bias: model.layer2.bias.flattened().scalars,\n",
    "//                      inputChannels: 64,\n",
    "//                      outputChannels: 32)\n",
    "//         ReLu(name: \"Relu2\",\n",
    "//              input: [\"outDense2\"],\n",
    "//              output: [\"outRelu2\"])\n",
    "//         InnerProduct(name: \"dense3\",\n",
    "//                      input: [\"outRelu2\"],\n",
    "//                      output: [\"output\"],\n",
    "//                      weight: model.layer3.weight.transposed().flattened().scalars,\n",
    "//                      bias: model.layer3.bias.flattened().scalars,\n",
    "//                      inputChannels: 32,\n",
    "//                      outputChannels: 1)\n",
    "//     }\n",
    "// }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "// let coreMLData = coremlModel.coreMLData\n",
    "// try! coreMLData!.write(to: URL(fileURLWithPath: \"../model/s4tf_train_model.mlmodel\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "S4TF_House.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
