{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages:\n",
      "\t.package(url: \"https://github.com/JacopoMangiavacchi/SwiftCoreMLTools.git\", from: \"0.0.6\")\n",
      "\t\tSwiftCoreMLTools\n",
      "\t.package(url: \"https://github.com/dduan/Just.git\", from: \"0.8.0\")\n",
      "\t\tJust\n",
      "With SwiftPM flags: ['-c', 'release']\n",
      "Working in: /tmp/tmpxbchanhm/swift-install\n",
      "Fetching https://github.com/JacopoMangiavacchi/SwiftCoreMLTools.git\n",
      "Fetching https://github.com/dduan/Just.git\n",
      "Fetching https://github.com/apple/swift-protobuf.git\n",
      "Cloning https://github.com/JacopoMangiavacchi/SwiftCoreMLTools.git\n",
      "Resolving https://github.com/JacopoMangiavacchi/SwiftCoreMLTools.git at 0.0.6\n",
      "Cloning https://github.com/apple/swift-protobuf.git\n",
      "Resolving https://github.com/apple/swift-protobuf.git at 1.8.0\n",
      "Cloning https://github.com/dduan/Just.git\n",
      "Resolving https://github.com/dduan/Just.git at 0.8.0\n",
      "[1/3] Compiling Just Just.swift\n",
      "[2/3] Compiling SwiftProtobuf AnyMessageStorage.swift\n",
      "[3/4] Compiling SwiftCoreMLTools Activations.swift\n",
      "[4/5] Compiling jupyterInstalledPackages jupyterInstalledPackages.swift\n",
      "[5/5] Linking libjupyterInstalledPackages.so\n",
      "Initializing Swift...\n",
      "Installation complete!\n"
     ]
    }
   ],
   "source": [
    "%install-swiftpm-flags -c release\n",
    "%install '.package(url: \"https://github.com/JacopoMangiavacchi/SwiftCoreMLTools.git\", from: \"0.0.6\")' SwiftCoreMLTools\n",
    "%install '.package(url: \"https://github.com/dduan/Just.git\", from: \"0.8.0\")' Just"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TO4FT9bUohHx"
   },
   "outputs": [],
   "source": [
    "import Foundation\n",
    "import SwiftCoreMLTools\n",
    "import TensorFlow\n",
    "import Just"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Download\n",
    "\n",
    "Boston house prices dataset\n",
    "---------------------------\n",
    "\n",
    "**Data Set Characteristics:**  \n",
    "\n",
    "    :Number of Instances: 506 \n",
    "\n",
    "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
    "\n",
    "    :Attribute Information (in order):\n",
    "        - CRIM     per capita crime rate by town\n",
    "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "        - INDUS    proportion of non-retail business acres per town\n",
    "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "        - NOX      nitric oxides concentration (parts per 10 million)\n",
    "        - RM       average number of rooms per dwelling\n",
    "        - AGE      proportion of owner-occupied units built prior to 1940\n",
    "        - DIS      weighted distances to five Boston employment centres\n",
    "        - RAD      index of accessibility to radial highways\n",
    "        - TAX      full-value property-tax rate per ten thousand dollars\n",
    "        - PTRATIO  pupil-teacher ratio by town\n",
    "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "        - LSTAT    % lower status of the population\n",
    "        - MEDV     Median value of owner-occupied homes in a thousand dollar\n",
    "\n",
    "    :Missing Attribute Values: None\n",
    "\n",
    "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
    "\n",
    "This is a copy of UCI ML housing dataset.\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "// if let cts = Just.get(URL(string: \"https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\")!).content {\n",
    "//     try! cts.write(to: URL(fileURLWithPath:\"../data/housing.csv\"))\n",
    "// }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "let data = try String(contentsOfFile:\"../data/housing.csv\", encoding: String.Encoding.utf8)\n",
    "let dataRecords: [[Float]] = data.split(separator: \"\\n\").map{ String($0).split(separator: \" \").compactMap{ Float(String($0)) } }\n",
    "\n",
    "let numRecords = dataRecords.count\n",
    "let numColumns = dataRecords[0].count\n",
    "\n",
    "var index = Set<Int>()\n",
    "\n",
    "while index.count < numRecords {\n",
    "    index.insert(Int.random(in: 0..<numRecords))\n",
    "}\n",
    "\n",
    "let randomDataRecords = index.map{ dataRecords[$0] }\n",
    "\n",
    "let dataFeatures = randomDataRecords.map{ Array($0[0..<numColumns-1]) }\n",
    "let dataLabels = randomDataRecords.map{ Array($0[(numColumns-1)...]) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Numerical Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "let categoricalColumns = [3, 8]\n",
    "let numericalColumns = [0, 1, 2, 4, 5, 6, 7, 9, 10, 11, 12]\n",
    "let numCategoricalFeatures = categoricalColumns.count\n",
    "let numNumericalFeatures = numericalColumns.count\n",
    "let numLabels = 1\n",
    "\n",
    "assert(numColumns == numCategoricalFeatures + numNumericalFeatures + 1)\n",
    "\n",
    "// Get Categorical Features\n",
    "let allCategoriesValues = dataFeatures.map{ row in categoricalColumns.map{ Int32(row[$0]) } }\n",
    "                                .reduce(into: Array(repeating: [Int32](), count: 2)){ total, value in\n",
    "                                    total[0].append(value[0])\n",
    "                                    total[1].append(value[1]) }\n",
    "                                .map{ Set($0).sorted() }\n",
    "\n",
    "let categoricalFeatures = dataFeatures.map{ row in categoricalColumns.map{ Int32(row[$0]) } }\n",
    "\n",
    "// Get Numerical Features\n",
    "let numericalFeatures = dataFeatures.map{ row in numericalColumns.map{ row[$0] } }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize Categorical Features with Ordinal values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "var categoricalValues = Array(repeating: Set<Int32>(), count: 2)\n",
    "\n",
    "for record in categoricalFeatures {\n",
    "    categoricalValues[0].insert(record[0])\n",
    "    categoricalValues[1].insert(record[1])\n",
    "}\n",
    "\n",
    "let sortedCategoricalValues = [categoricalValues[0].sorted(), categoricalValues[1].sorted()]\n",
    "\n",
    "let ordinalCategoricalFeatures = categoricalFeatures.map{ [Int32(sortedCategoricalValues[0].firstIndex(of:$0[0])!), \n",
    "                                                           Int32(sortedCategoricalValues[1].firstIndex(of:$0[1])!)] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "let trainPercentage:Float = 0.8\n",
    "let numTrainRecords = Int(ceil(Float(numRecords) * trainPercentage))\n",
    "let numTestRecords = numRecords - numTrainRecords\n",
    "\n",
    "func matrixTranspose<T>(_ matrix: [[T]]) -> [[T]] {\n",
    "    if matrix.isEmpty {return matrix}\n",
    "    var result = [[T]]()\n",
    "    for index in 0..<matrix.first!.count {\n",
    "        result.append(matrix.map{$0[index]})\n",
    "    }\n",
    "    return result\n",
    "}\n",
    "\n",
    "let xCategoricalAllTrain = matrixTranspose(Array(ordinalCategoricalFeatures[0..<numTrainRecords]))\n",
    "let xCategoricalAllTest = matrixTranspose(Array(ordinalCategoricalFeatures[numTrainRecords...]))\n",
    "let xNumericalAllTrain = Array(Array(numericalFeatures[0..<numTrainRecords]).joined())\n",
    "let xNumericalAllTest = Array(Array(numericalFeatures[numTrainRecords...]).joined())\n",
    "let yAllTrain = Array(Array(dataLabels[0..<numTrainRecords]).joined())\n",
    "let yAllTest = Array(Array(dataLabels[numTrainRecords...]).joined())\n",
    "\n",
    "let XCategoricalTrain = xCategoricalAllTrain.enumerated().map{ (offset, element) in \n",
    "    Tensor<Int32>(element).reshaped(to: TensorShape([numTrainRecords, 1]))\n",
    "}\n",
    "let XCategoricalTest = xCategoricalAllTest.enumerated().map{ (offset, element) in \n",
    "    Tensor<Int32>(element).reshaped(to: TensorShape([numTestRecords, 1]))\n",
    "}\n",
    "\n",
    "let XNumericalTrainDeNorm = Tensor<Float>(xNumericalAllTrain).reshaped(to: TensorShape([numTrainRecords, numNumericalFeatures]))\n",
    "let XNumericalTestDeNorm = Tensor<Float>(xNumericalAllTest).reshaped(to: TensorShape([numTestRecords, numNumericalFeatures]))\n",
    "let YTrain = Tensor<Float>(yAllTrain).reshaped(to: TensorShape([numTrainRecords, numLabels]))\n",
    "let YTest = Tensor<Float>(yAllTest).reshaped(to: TensorShape([numTestRecords, numLabels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.568779,  11.25679, 11.137291, 0.5546997,   6.27381,   68.3178,  3.818542, 402.84445,\r\n",
      "   18.41015, 358.97717,  12.61089]] [[   8.600502,   22.944748,   6.9644384, 0.117559254,  0.72180307,   28.166008,   2.0910063,\r\n",
      "    168.27527,    2.141634,    88.84905,   7.2150693]]\r\n"
     ]
    }
   ],
   "source": [
    "let mean = XNumericalTrainDeNorm.mean(alongAxes: 0)\n",
    "let std = XNumericalTrainDeNorm.standardDeviation(alongAxes: 0)\n",
    "\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "let XNumericalTrain = (XNumericalTrainDeNorm - mean)/std\n",
    "let XNumericalTest = (XNumericalTestDeNorm - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shapes [405, 11] [405, 1] [405, 1] [405, 1]\r\n",
      "Testing shapes  [101, 11] [101, 1] [101, 1] [101, 1]\r\n"
     ]
    }
   ],
   "source": [
    "print(\"Training shapes \\(XNumericalTrain.shape) \\(XCategoricalTrain[0].shape) \\(XCategoricalTrain[1].shape) \\(YTrain.shape)\")\n",
    "print(\"Testing shapes  \\(XNumericalTest.shape) \\(XCategoricalTest[0].shape) \\(XCategoricalTest[1].shape) \\(YTest.shape)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HDJZCCgqohIC"
   },
   "outputs": [],
   "source": [
    "struct MultiInputs<N: Differentiable, C>: Differentiable {\n",
    "  var numerical: N\n",
    "  \n",
    "  @noDerivative\n",
    "  var categorical: C\n",
    "\n",
    "  @differentiable\n",
    "  init(numerical: N, categorical: C) {\n",
    "    self.numerical = numerical\n",
    "    self.categorical = categorical\n",
    "  }\n",
    "}\n",
    "\n",
    "struct RegressionModel: Module {\n",
    "    var embedding1 = TensorFlow.Embedding<Float>(vocabularySize: 2, embeddingSize: 2)\n",
    "    var embedding2 = TensorFlow.Embedding<Float>(vocabularySize: 9, embeddingSize: 5)\n",
    "    var allInputConcatLayer = Dense<Float>(inputSize: (11 + 2 + 5), outputSize: 64, activation: relu)\n",
    "    var hiddenLayer = Dense<Float>(inputSize: 64, outputSize: 32, activation: relu)\n",
    "    var outputLayer = Dense<Float>(inputSize: 32, outputSize: 1)\n",
    "    \n",
    "    @differentiable\n",
    "    func callAsFunction(_ input: MultiInputs<[Tensor<Float>], [Tensor<Int32>]>) -> Tensor<Float> {\n",
    "        let embeddingOutput1 = embedding1(input.categorical[0])\n",
    "        let embeddingOutput1Reshaped = embeddingOutput1.reshaped(to: \n",
    "            TensorShape([embeddingOutput1.shape[0], embeddingOutput1.shape[2]]))\n",
    "        let embeddingOutput2 = embedding2(input.categorical[1])\n",
    "        let embeddingOutput2Reshaped = embeddingOutput2.reshaped(to: \n",
    "            TensorShape([embeddingOutput2.shape[0], embeddingOutput2.shape[2]]))\n",
    "        let allConcat = Tensor<Float>(concatenating: [input.numerical[0], embeddingOutput1Reshaped, embeddingOutput2Reshaped], alongAxis: 1)\n",
    "        return allConcat.sequenced(through: allInputConcatLayer, hiddenLayer, outputLayer)\n",
    "    }\n",
    "}\n",
    "\n",
    "var model = RegressionModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JK0Vj7bSohIF"
   },
   "outputs": [],
   "source": [
    "let optimizer = RMSProp(for: model, learningRate: 0.001)\n",
    "Context.local.learningPhase = .training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gY8C7yHJohIH"
   },
   "outputs": [],
   "source": [
    "let epochCount = 500\n",
    "let batchSize = 32\n",
    "let numberOfBatch = Int(ceil(Double(numTrainRecords) / Double(batchSize)))\n",
    "let shuffle = true\n",
    "\n",
    "func mae(predictions: Tensor<Float>, truths: Tensor<Float>) -> Float {\n",
    "    return abs(Tensor<Float>(predictions - truths)).mean().scalarized()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "L9bU9HsdohIK",
    "outputId": "692b81c5-3286-4e7c-9246-eb56e6a3eaee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: MSE: 555.85724, MAE: 21.593758\n",
      "Epoch 2: MSE: 494.58957, MAE: 20.079403\n",
      "Epoch 3: MSE: 417.35944, MAE: 18.056143\n",
      "Epoch 4: MSE: 323.04916, MAE: 15.4796915\n",
      "Epoch 5: MSE: 225.07655, MAE: 12.439347\n",
      "Epoch 6: MSE: 141.13112, MAE: 9.17065\n",
      "Epoch 7: MSE: 81.2541, MAE: 6.3849134\n",
      "Epoch 8: MSE: 50.59609, MAE: 4.8456607\n",
      "Epoch 9: MSE: 38.810886, MAE: 4.300005\n",
      "Epoch 10: MSE: 32.426266, MAE: 3.9352217\n",
      "Epoch 11: MSE: 28.155764, MAE: 3.6364465\n",
      "Epoch 12: MSE: 24.99872, MAE: 3.4038403\n",
      "Epoch 13: MSE: 22.808481, MAE: 3.258329\n",
      "Epoch 14: MSE: 21.320107, MAE: 3.1203814\n",
      "Epoch 15: MSE: 20.33838, MAE: 3.0329657\n",
      "Epoch 16: MSE: 19.368086, MAE: 2.9625475\n",
      "Epoch 17: MSE: 18.712317, MAE: 2.9187393\n",
      "Epoch 18: MSE: 18.18215, MAE: 2.897068\n",
      "Epoch 19: MSE: 17.590696, MAE: 2.840684\n",
      "Epoch 20: MSE: 17.123863, MAE: 2.801013\n",
      "Epoch 21: MSE: 16.708498, MAE: 2.787481\n",
      "Epoch 22: MSE: 16.479849, MAE: 2.7366984\n",
      "Epoch 23: MSE: 15.963711, MAE: 2.702882\n",
      "Epoch 24: MSE: 15.681037, MAE: 2.6511755\n",
      "Epoch 25: MSE: 15.3159075, MAE: 2.6199803\n",
      "Epoch 26: MSE: 15.048765, MAE: 2.603884\n",
      "Epoch 27: MSE: 14.774313, MAE: 2.5636797\n",
      "Epoch 28: MSE: 14.383997, MAE: 2.5322752\n",
      "Epoch 29: MSE: 14.094269, MAE: 2.4929419\n",
      "Epoch 30: MSE: 14.04831, MAE: 2.45698\n",
      "Epoch 31: MSE: 13.5525465, MAE: 2.427428\n",
      "Epoch 32: MSE: 13.360056, MAE: 2.3961673\n",
      "Epoch 33: MSE: 13.060603, MAE: 2.3792965\n",
      "Epoch 34: MSE: 12.794479, MAE: 2.3448694\n",
      "Epoch 35: MSE: 12.587219, MAE: 2.324917\n",
      "Epoch 36: MSE: 12.4776325, MAE: 2.283457\n",
      "Epoch 37: MSE: 12.273008, MAE: 2.27912\n",
      "Epoch 38: MSE: 12.042525, MAE: 2.260644\n",
      "Epoch 39: MSE: 11.687882, MAE: 2.2348597\n",
      "Epoch 40: MSE: 11.678643, MAE: 2.2003405\n",
      "Epoch 41: MSE: 11.44829, MAE: 2.1890025\n",
      "Epoch 42: MSE: 11.401035, MAE: 2.1732385\n",
      "Epoch 43: MSE: 11.197388, MAE: 2.151497\n",
      "Epoch 44: MSE: 10.971459, MAE: 2.1342485\n",
      "Epoch 45: MSE: 10.804692, MAE: 2.1171064\n",
      "Epoch 46: MSE: 10.744232, MAE: 2.1036553\n",
      "Epoch 47: MSE: 10.552439, MAE: 2.0912504\n",
      "Epoch 48: MSE: 10.323619, MAE: 2.0600572\n",
      "Epoch 49: MSE: 10.441544, MAE: 2.0651293\n",
      "Epoch 50: MSE: 10.304908, MAE: 2.062113\n",
      "Epoch 51: MSE: 10.143818, MAE: 2.048127\n",
      "Epoch 52: MSE: 10.101333, MAE: 2.0185328\n",
      "Epoch 53: MSE: 9.930281, MAE: 2.0132601\n",
      "Epoch 54: MSE: 9.8788595, MAE: 2.0107775\n",
      "Epoch 55: MSE: 9.804633, MAE: 1.9995414\n",
      "Epoch 56: MSE: 9.578923, MAE: 1.9779713\n",
      "Epoch 57: MSE: 9.487449, MAE: 1.9544368\n",
      "Epoch 58: MSE: 9.527463, MAE: 1.9568603\n",
      "Epoch 59: MSE: 9.216089, MAE: 1.9450063\n",
      "Epoch 60: MSE: 9.222918, MAE: 1.9453765\n",
      "Epoch 61: MSE: 9.272218, MAE: 1.9346161\n",
      "Epoch 62: MSE: 8.963847, MAE: 1.9105303\n",
      "Epoch 63: MSE: 8.883516, MAE: 1.9038317\n",
      "Epoch 64: MSE: 8.87229, MAE: 1.9107717\n",
      "Epoch 65: MSE: 8.817508, MAE: 1.8812093\n",
      "Epoch 66: MSE: 8.694054, MAE: 1.8915423\n",
      "Epoch 67: MSE: 8.642503, MAE: 1.8688312\n",
      "Epoch 68: MSE: 8.642321, MAE: 1.867536\n",
      "Epoch 69: MSE: 8.558091, MAE: 1.8535568\n",
      "Epoch 70: MSE: 8.517382, MAE: 1.8422648\n",
      "Epoch 71: MSE: 8.357763, MAE: 1.8322263\n",
      "Epoch 72: MSE: 8.34047, MAE: 1.85213\n",
      "Epoch 73: MSE: 8.266052, MAE: 1.8269458\n",
      "Epoch 74: MSE: 8.154316, MAE: 1.8164732\n",
      "Epoch 75: MSE: 8.184952, MAE: 1.8072804\n",
      "Epoch 76: MSE: 8.016485, MAE: 1.8022172\n",
      "Epoch 77: MSE: 7.9411044, MAE: 1.7866064\n",
      "Epoch 78: MSE: 7.9278507, MAE: 1.7869911\n",
      "Epoch 79: MSE: 7.7468014, MAE: 1.7878191\n",
      "Epoch 80: MSE: 7.8899603, MAE: 1.7671859\n",
      "Epoch 81: MSE: 7.742079, MAE: 1.7775072\n",
      "Epoch 82: MSE: 7.787708, MAE: 1.7663283\n",
      "Epoch 83: MSE: 7.664235, MAE: 1.7539719\n",
      "Epoch 84: MSE: 7.672845, MAE: 1.7414073\n",
      "Epoch 85: MSE: 7.574732, MAE: 1.7497588\n",
      "Epoch 86: MSE: 7.5770082, MAE: 1.7392355\n",
      "Epoch 87: MSE: 7.4481754, MAE: 1.7247798\n",
      "Epoch 88: MSE: 7.311116, MAE: 1.7243785\n",
      "Epoch 89: MSE: 7.318839, MAE: 1.7182478\n",
      "Epoch 90: MSE: 7.3077035, MAE: 1.7090358\n",
      "Epoch 91: MSE: 7.2016363, MAE: 1.7014375\n",
      "Epoch 92: MSE: 7.2311354, MAE: 1.7157016\n",
      "Epoch 93: MSE: 7.130778, MAE: 1.7190347\n",
      "Epoch 94: MSE: 7.0571537, MAE: 1.6872069\n",
      "Epoch 95: MSE: 7.068458, MAE: 1.6845104\n",
      "Epoch 96: MSE: 6.95115, MAE: 1.6805001\n",
      "Epoch 97: MSE: 7.06225, MAE: 1.684945\n",
      "Epoch 98: MSE: 6.818593, MAE: 1.6613704\n",
      "Epoch 99: MSE: 6.823071, MAE: 1.6748208\n",
      "Epoch 100: MSE: 6.6935472, MAE: 1.6600306\n",
      "Epoch 101: MSE: 6.7256627, MAE: 1.6437341\n",
      "Epoch 102: MSE: 6.7359104, MAE: 1.6486396\n",
      "Epoch 103: MSE: 6.655662, MAE: 1.6424572\n",
      "Epoch 104: MSE: 6.574567, MAE: 1.6402022\n",
      "Epoch 105: MSE: 6.4259253, MAE: 1.6239307\n",
      "Epoch 106: MSE: 6.5053635, MAE: 1.6314375\n",
      "Epoch 107: MSE: 6.446917, MAE: 1.618574\n",
      "Epoch 108: MSE: 6.4218926, MAE: 1.6265724\n",
      "Epoch 109: MSE: 6.374192, MAE: 1.5984018\n",
      "Epoch 110: MSE: 6.3307767, MAE: 1.5944699\n",
      "Epoch 111: MSE: 6.368044, MAE: 1.5993006\n",
      "Epoch 112: MSE: 6.313674, MAE: 1.599436\n",
      "Epoch 113: MSE: 6.22837, MAE: 1.585225\n",
      "Epoch 114: MSE: 6.2073317, MAE: 1.578148\n",
      "Epoch 115: MSE: 6.063805, MAE: 1.574898\n",
      "Epoch 116: MSE: 6.121516, MAE: 1.570355\n",
      "Epoch 117: MSE: 6.113904, MAE: 1.5721194\n",
      "Epoch 118: MSE: 6.042846, MAE: 1.5800068\n",
      "Epoch 119: MSE: 6.04988, MAE: 1.5575589\n",
      "Epoch 120: MSE: 5.956968, MAE: 1.5494944\n",
      "Epoch 121: MSE: 5.912646, MAE: 1.5433166\n",
      "Epoch 122: MSE: 5.980167, MAE: 1.5484129\n",
      "Epoch 123: MSE: 5.893296, MAE: 1.5377833\n",
      "Epoch 124: MSE: 5.9124546, MAE: 1.5331099\n",
      "Epoch 125: MSE: 5.880897, MAE: 1.5259\n",
      "Epoch 126: MSE: 5.7701945, MAE: 1.5078337\n",
      "Epoch 127: MSE: 5.6937895, MAE: 1.5192983\n",
      "Epoch 128: MSE: 5.609162, MAE: 1.527523\n",
      "Epoch 129: MSE: 5.646531, MAE: 1.5033295\n",
      "Epoch 130: MSE: 5.6330285, MAE: 1.5022857\n",
      "Epoch 131: MSE: 5.721741, MAE: 1.4971006\n",
      "Epoch 132: MSE: 5.4001007, MAE: 1.4939554\n",
      "Epoch 133: MSE: 5.589584, MAE: 1.4929038\n",
      "Epoch 134: MSE: 5.3989186, MAE: 1.488811\n",
      "Epoch 135: MSE: 5.393918, MAE: 1.4878656\n",
      "Epoch 136: MSE: 5.619212, MAE: 1.4762228\n",
      "Epoch 137: MSE: 5.3429923, MAE: 1.4706737\n",
      "Epoch 138: MSE: 5.428337, MAE: 1.4603553\n",
      "Epoch 139: MSE: 5.2944994, MAE: 1.4698484\n",
      "Epoch 140: MSE: 5.3940244, MAE: 1.4520415\n",
      "Epoch 141: MSE: 5.3865027, MAE: 1.4508585\n",
      "Epoch 142: MSE: 5.1442957, MAE: 1.4504794\n",
      "Epoch 143: MSE: 5.314048, MAE: 1.4503596\n",
      "Epoch 144: MSE: 5.1640797, MAE: 1.4436406\n",
      "Epoch 145: MSE: 5.1702037, MAE: 1.4348515\n",
      "Epoch 146: MSE: 5.141134, MAE: 1.4285276\n",
      "Epoch 147: MSE: 5.148885, MAE: 1.4209844\n",
      "Epoch 148: MSE: 5.0787005, MAE: 1.4216607\n",
      "Epoch 149: MSE: 5.1623735, MAE: 1.4108053\n",
      "Epoch 150: MSE: 5.03977, MAE: 1.4209892\n",
      "Epoch 151: MSE: 4.8830814, MAE: 1.4180069\n",
      "Epoch 152: MSE: 5.045019, MAE: 1.400713\n",
      "Epoch 153: MSE: 4.899829, MAE: 1.3873242\n",
      "Epoch 154: MSE: 4.9213443, MAE: 1.3932906\n",
      "Epoch 155: MSE: 4.6341815, MAE: 1.3791627\n",
      "Epoch 156: MSE: 4.866535, MAE: 1.390055\n",
      "Epoch 157: MSE: 5.060267, MAE: 1.3839295\n",
      "Epoch 158: MSE: 4.657452, MAE: 1.3765919\n",
      "Epoch 159: MSE: 4.7088842, MAE: 1.3788873\n",
      "Epoch 160: MSE: 4.822582, MAE: 1.3721267\n",
      "Epoch 161: MSE: 4.810513, MAE: 1.3639163\n",
      "Epoch 162: MSE: 4.654019, MAE: 1.3490611\n",
      "Epoch 163: MSE: 4.5388546, MAE: 1.3542485\n",
      "Epoch 164: MSE: 4.712871, MAE: 1.3397535\n",
      "Epoch 165: MSE: 4.619023, MAE: 1.3501027\n",
      "Epoch 166: MSE: 4.6915975, MAE: 1.3404129\n",
      "Epoch 167: MSE: 4.532166, MAE: 1.3463012\n",
      "Epoch 168: MSE: 4.542796, MAE: 1.3342019\n",
      "Epoch 169: MSE: 4.649566, MAE: 1.3381801\n",
      "Epoch 170: MSE: 4.501375, MAE: 1.3229326\n",
      "Epoch 171: MSE: 4.5356336, MAE: 1.3235164\n",
      "Epoch 172: MSE: 4.4076915, MAE: 1.325472\n",
      "Epoch 173: MSE: 4.587308, MAE: 1.3117269\n",
      "Epoch 174: MSE: 4.324577, MAE: 1.3092973\n",
      "Epoch 175: MSE: 4.5834394, MAE: 1.3062178\n",
      "Epoch 176: MSE: 4.2595935, MAE: 1.307275\n",
      "Epoch 177: MSE: 4.3781605, MAE: 1.3035986\n",
      "Epoch 178: MSE: 4.3406305, MAE: 1.3016293\n",
      "Epoch 179: MSE: 4.472609, MAE: 1.3093382\n",
      "Epoch 180: MSE: 4.302409, MAE: 1.2971517\n",
      "Epoch 181: MSE: 4.2274084, MAE: 1.2840406\n",
      "Epoch 182: MSE: 4.449339, MAE: 1.2972745\n",
      "Epoch 183: MSE: 4.212659, MAE: 1.276496\n",
      "Epoch 184: MSE: 4.2764683, MAE: 1.2816792\n",
      "Epoch 185: MSE: 4.315158, MAE: 1.2846627\n",
      "Epoch 186: MSE: 4.1470284, MAE: 1.2721277\n",
      "Epoch 187: MSE: 4.1896076, MAE: 1.2689764\n",
      "Epoch 188: MSE: 4.2338743, MAE: 1.2689906\n",
      "Epoch 189: MSE: 4.0723257, MAE: 1.2625071\n",
      "Epoch 190: MSE: 4.163093, MAE: 1.2651662\n",
      "Epoch 191: MSE: 4.2101474, MAE: 1.2557024\n",
      "Epoch 192: MSE: 4.1500626, MAE: 1.2546299\n",
      "Epoch 193: MSE: 4.0477405, MAE: 1.2613608\n",
      "Epoch 194: MSE: 4.0107536, MAE: 1.2622288\n",
      "Epoch 195: MSE: 4.2565317, MAE: 1.2447655\n",
      "Epoch 196: MSE: 4.0771265, MAE: 1.2510942\n",
      "Epoch 197: MSE: 4.052493, MAE: 1.2435386\n",
      "Epoch 198: MSE: 4.0088053, MAE: 1.2439469\n",
      "Epoch 199: MSE: 4.012352, MAE: 1.2451369\n",
      "Epoch 200: MSE: 3.994044, MAE: 1.2441481\n",
      "Epoch 201: MSE: 3.9644656, MAE: 1.2308713\n",
      "Epoch 202: MSE: 3.92049, MAE: 1.2295572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203: MSE: 4.0677505, MAE: 1.2310504\n",
      "Epoch 204: MSE: 3.8893647, MAE: 1.2247624\n",
      "Epoch 205: MSE: 3.8471096, MAE: 1.2164326\n",
      "Epoch 206: MSE: 3.9869483, MAE: 1.2223322\n",
      "Epoch 207: MSE: 3.7827413, MAE: 1.210011\n",
      "Epoch 208: MSE: 3.9355226, MAE: 1.2213457\n",
      "Epoch 209: MSE: 3.7930295, MAE: 1.2071694\n",
      "Epoch 210: MSE: 3.8979528, MAE: 1.221236\n",
      "Epoch 211: MSE: 3.8424923, MAE: 1.2112267\n",
      "Epoch 212: MSE: 4.0192432, MAE: 1.206017\n",
      "Epoch 213: MSE: 3.6404872, MAE: 1.2104465\n",
      "Epoch 214: MSE: 3.7586617, MAE: 1.2035306\n",
      "Epoch 215: MSE: 3.8147783, MAE: 1.1972021\n",
      "Epoch 216: MSE: 3.6894784, MAE: 1.1882695\n",
      "Epoch 217: MSE: 3.889833, MAE: 1.1893332\n",
      "Epoch 218: MSE: 3.8685403, MAE: 1.1804007\n",
      "Epoch 219: MSE: 3.660243, MAE: 1.176785\n",
      "Epoch 220: MSE: 3.591872, MAE: 1.181987\n",
      "Epoch 221: MSE: 3.616466, MAE: 1.1735991\n",
      "Epoch 222: MSE: 3.589189, MAE: 1.1761128\n",
      "Epoch 223: MSE: 3.6083422, MAE: 1.1791081\n",
      "Epoch 224: MSE: 3.763592, MAE: 1.1755822\n",
      "Epoch 225: MSE: 3.7189205, MAE: 1.1788684\n",
      "Epoch 226: MSE: 3.614739, MAE: 1.1773599\n",
      "Epoch 227: MSE: 3.7429123, MAE: 1.1724839\n",
      "Epoch 228: MSE: 3.6820068, MAE: 1.172453\n",
      "Epoch 229: MSE: 3.4883218, MAE: 1.1557128\n",
      "Epoch 230: MSE: 3.530373, MAE: 1.1533126\n",
      "Epoch 231: MSE: 3.6560602, MAE: 1.1699704\n",
      "Epoch 232: MSE: 3.6357298, MAE: 1.1665604\n",
      "Epoch 233: MSE: 3.617465, MAE: 1.1612272\n",
      "Epoch 234: MSE: 3.6225765, MAE: 1.1565539\n",
      "Epoch 235: MSE: 3.6891646, MAE: 1.160237\n",
      "Epoch 236: MSE: 3.5489836, MAE: 1.1614197\n",
      "Epoch 237: MSE: 3.500351, MAE: 1.162532\n",
      "Epoch 238: MSE: 3.4994764, MAE: 1.1329962\n",
      "Epoch 239: MSE: 3.5584185, MAE: 1.1461685\n",
      "Epoch 240: MSE: 3.67422, MAE: 1.1535192\n",
      "Epoch 241: MSE: 3.4574893, MAE: 1.1424223\n",
      "Epoch 242: MSE: 3.5599694, MAE: 1.1386667\n",
      "Epoch 243: MSE: 3.4577513, MAE: 1.1426905\n",
      "Epoch 244: MSE: 3.5155058, MAE: 1.144321\n",
      "Epoch 245: MSE: 3.551687, MAE: 1.1293668\n",
      "Epoch 246: MSE: 3.4689093, MAE: 1.1376671\n",
      "Epoch 247: MSE: 3.4781575, MAE: 1.1377847\n",
      "Epoch 248: MSE: 3.5158815, MAE: 1.1262907\n",
      "Epoch 249: MSE: 3.3826604, MAE: 1.1253524\n",
      "Epoch 250: MSE: 3.4487891, MAE: 1.1194495\n",
      "Epoch 251: MSE: 3.2223132, MAE: 1.1124469\n",
      "Epoch 252: MSE: 3.6099527, MAE: 1.1229699\n",
      "Epoch 253: MSE: 3.3708217, MAE: 1.1128479\n",
      "Epoch 254: MSE: 3.3773923, MAE: 1.1098166\n",
      "Epoch 255: MSE: 3.2151613, MAE: 1.1047764\n",
      "Epoch 256: MSE: 3.3724272, MAE: 1.1187652\n",
      "Epoch 257: MSE: 3.3206885, MAE: 1.1165239\n",
      "Epoch 258: MSE: 3.5351584, MAE: 1.1195728\n",
      "Epoch 259: MSE: 3.316876, MAE: 1.1114075\n",
      "Epoch 260: MSE: 3.2986803, MAE: 1.1060319\n",
      "Epoch 261: MSE: 3.396974, MAE: 1.1123605\n",
      "Epoch 262: MSE: 3.3495145, MAE: 1.1043596\n",
      "Epoch 263: MSE: 3.3648915, MAE: 1.098118\n",
      "Epoch 264: MSE: 3.202619, MAE: 1.1031522\n",
      "Epoch 265: MSE: 3.2618022, MAE: 1.0892738\n",
      "Epoch 266: MSE: 3.212302, MAE: 1.0845755\n",
      "Epoch 267: MSE: 3.3023887, MAE: 1.0859332\n",
      "Epoch 268: MSE: 3.256073, MAE: 1.0883855\n",
      "Epoch 269: MSE: 3.3407, MAE: 1.0856053\n",
      "Epoch 270: MSE: 3.2733054, MAE: 1.0817186\n",
      "Epoch 271: MSE: 3.2730267, MAE: 1.0907328\n",
      "Epoch 272: MSE: 3.1640532, MAE: 1.0837814\n",
      "Epoch 273: MSE: 3.2090697, MAE: 1.0844011\n",
      "Epoch 274: MSE: 3.191517, MAE: 1.0718344\n",
      "Epoch 275: MSE: 3.1099257, MAE: 1.0813216\n",
      "Epoch 276: MSE: 3.0381727, MAE: 1.0731349\n",
      "Epoch 277: MSE: 3.184914, MAE: 1.0738047\n",
      "Epoch 278: MSE: 3.2872305, MAE: 1.0832338\n",
      "Epoch 279: MSE: 3.2418947, MAE: 1.0730895\n",
      "Epoch 280: MSE: 3.1547275, MAE: 1.0783627\n",
      "Epoch 281: MSE: 3.2225306, MAE: 1.060356\n",
      "Epoch 282: MSE: 3.135268, MAE: 1.0634114\n",
      "Epoch 283: MSE: 3.1178904, MAE: 1.0698712\n",
      "Epoch 284: MSE: 3.0704532, MAE: 1.0590098\n",
      "Epoch 285: MSE: 3.1613176, MAE: 1.0811496\n",
      "Epoch 286: MSE: 3.2064104, MAE: 1.0564512\n",
      "Epoch 287: MSE: 3.0404205, MAE: 1.0539367\n",
      "Epoch 288: MSE: 3.0497346, MAE: 1.0477068\n",
      "Epoch 289: MSE: 3.01449, MAE: 1.0506518\n",
      "Epoch 290: MSE: 2.9457872, MAE: 1.0435388\n",
      "Epoch 291: MSE: 3.173673, MAE: 1.0561414\n",
      "Epoch 292: MSE: 3.1631517, MAE: 1.0567838\n",
      "Epoch 293: MSE: 2.9234433, MAE: 1.0457388\n",
      "Epoch 294: MSE: 3.1874404, MAE: 1.0533819\n",
      "Epoch 295: MSE: 3.0206451, MAE: 1.0483868\n",
      "Epoch 296: MSE: 3.0341911, MAE: 1.0450784\n",
      "Epoch 297: MSE: 3.112559, MAE: 1.0348314\n",
      "Epoch 298: MSE: 3.0689096, MAE: 1.0477219\n",
      "Epoch 299: MSE: 2.93788, MAE: 1.0458987\n",
      "Epoch 300: MSE: 3.0245771, MAE: 1.0357106\n",
      "Epoch 301: MSE: 2.8631155, MAE: 1.0245416\n",
      "Epoch 302: MSE: 2.9932203, MAE: 1.0391852\n",
      "Epoch 303: MSE: 3.160904, MAE: 1.0354066\n",
      "Epoch 304: MSE: 2.8978362, MAE: 1.028049\n",
      "Epoch 305: MSE: 2.810429, MAE: 1.0251281\n",
      "Epoch 306: MSE: 2.979687, MAE: 1.0122098\n",
      "Epoch 307: MSE: 2.9500334, MAE: 1.0254463\n",
      "Epoch 308: MSE: 2.9259584, MAE: 1.016579\n",
      "Epoch 309: MSE: 2.8465738, MAE: 1.0160184\n",
      "Epoch 310: MSE: 3.027946, MAE: 1.0238357\n",
      "Epoch 311: MSE: 2.8895128, MAE: 1.0264264\n",
      "Epoch 312: MSE: 2.9251275, MAE: 1.0257366\n",
      "Epoch 313: MSE: 2.904926, MAE: 1.0044376\n",
      "Epoch 314: MSE: 2.8597853, MAE: 1.0067925\n",
      "Epoch 315: MSE: 2.823705, MAE: 1.0099548\n",
      "Epoch 316: MSE: 2.9258232, MAE: 1.0150841\n",
      "Epoch 317: MSE: 2.810877, MAE: 1.0067573\n",
      "Epoch 318: MSE: 2.8190413, MAE: 1.0058167\n",
      "Epoch 319: MSE: 2.9825041, MAE: 1.006643\n",
      "Epoch 320: MSE: 2.801285, MAE: 0.9962289\n",
      "Epoch 321: MSE: 2.870724, MAE: 1.0195422\n",
      "Epoch 322: MSE: 2.8783352, MAE: 0.99558026\n",
      "Epoch 323: MSE: 2.8554, MAE: 0.99204403\n",
      "Epoch 324: MSE: 2.8623316, MAE: 0.9964215\n",
      "Epoch 325: MSE: 2.7320137, MAE: 1.0003326\n",
      "Epoch 326: MSE: 2.7776628, MAE: 0.994725\n",
      "Epoch 327: MSE: 2.8375375, MAE: 0.9911767\n",
      "Epoch 328: MSE: 2.831261, MAE: 0.99062693\n",
      "Epoch 329: MSE: 2.8068156, MAE: 1.0044917\n",
      "Epoch 330: MSE: 2.900334, MAE: 0.9963979\n",
      "Epoch 331: MSE: 2.712174, MAE: 0.9747835\n",
      "Epoch 332: MSE: 2.782356, MAE: 0.9709841\n",
      "Epoch 333: MSE: 2.7265332, MAE: 0.98606\n",
      "Epoch 334: MSE: 2.927854, MAE: 0.9974042\n",
      "Epoch 335: MSE: 2.7372515, MAE: 0.9838038\n",
      "Epoch 336: MSE: 2.6988351, MAE: 0.9733925\n",
      "Epoch 337: MSE: 2.6374464, MAE: 0.98923236\n",
      "Epoch 338: MSE: 2.6821709, MAE: 0.9947954\n",
      "Epoch 339: MSE: 2.6807992, MAE: 0.97239864\n",
      "Epoch 340: MSE: 2.8060427, MAE: 0.9819451\n",
      "Epoch 341: MSE: 2.6740327, MAE: 0.9756797\n",
      "Epoch 342: MSE: 2.6855252, MAE: 0.98030037\n",
      "Epoch 343: MSE: 2.6101596, MAE: 0.9606211\n",
      "Epoch 344: MSE: 2.9336765, MAE: 0.9786993\n",
      "Epoch 345: MSE: 2.6612272, MAE: 0.967106\n",
      "Epoch 346: MSE: 2.7824073, MAE: 0.9581228\n",
      "Epoch 347: MSE: 2.655663, MAE: 0.97135544\n",
      "Epoch 348: MSE: 2.803816, MAE: 0.9862652\n",
      "Epoch 349: MSE: 2.6536179, MAE: 0.96157366\n",
      "Epoch 350: MSE: 2.6975057, MAE: 0.95963854\n",
      "Epoch 351: MSE: 2.5293124, MAE: 0.9739688\n",
      "Epoch 352: MSE: 2.6561606, MAE: 0.9740357\n",
      "Epoch 353: MSE: 2.6016018, MAE: 0.9546236\n",
      "Epoch 354: MSE: 2.5304704, MAE: 0.9535023\n",
      "Epoch 355: MSE: 2.8027291, MAE: 0.9579929\n",
      "Epoch 356: MSE: 2.520779, MAE: 0.9468757\n",
      "Epoch 357: MSE: 2.6929529, MAE: 0.9600221\n",
      "Epoch 358: MSE: 2.6209056, MAE: 0.95472175\n",
      "Epoch 359: MSE: 2.7199101, MAE: 0.9513858\n",
      "Epoch 360: MSE: 2.533526, MAE: 0.9541268\n",
      "Epoch 361: MSE: 2.578381, MAE: 0.9532866\n",
      "Epoch 362: MSE: 2.7269003, MAE: 0.95956546\n",
      "Epoch 363: MSE: 2.5028965, MAE: 0.9473722\n",
      "Epoch 364: MSE: 2.5120938, MAE: 0.9417459\n",
      "Epoch 365: MSE: 2.5577497, MAE: 0.9543971\n",
      "Epoch 366: MSE: 2.6121542, MAE: 0.94609916\n",
      "Epoch 367: MSE: 2.4318764, MAE: 0.937924\n",
      "Epoch 368: MSE: 2.36073, MAE: 0.9348939\n",
      "Epoch 369: MSE: 2.6136084, MAE: 0.9385631\n",
      "Epoch 370: MSE: 2.4566162, MAE: 0.9356155\n",
      "Epoch 371: MSE: 2.565759, MAE: 0.9418252\n",
      "Epoch 372: MSE: 2.5705981, MAE: 0.93811595\n",
      "Epoch 373: MSE: 2.573437, MAE: 0.93236375\n",
      "Epoch 374: MSE: 2.4325957, MAE: 0.9198596\n",
      "Epoch 375: MSE: 2.5353055, MAE: 0.93908256\n",
      "Epoch 376: MSE: 2.5061705, MAE: 0.93650466\n",
      "Epoch 377: MSE: 2.5000384, MAE: 0.91669494\n",
      "Epoch 378: MSE: 2.4820743, MAE: 0.92443943\n",
      "Epoch 379: MSE: 2.4679694, MAE: 0.9241139\n",
      "Epoch 380: MSE: 2.609495, MAE: 0.946686\n",
      "Epoch 381: MSE: 2.4834552, MAE: 0.93048793\n",
      "Epoch 382: MSE: 2.4596014, MAE: 0.91378725\n",
      "Epoch 383: MSE: 2.312598, MAE: 0.9040317\n",
      "Epoch 384: MSE: 2.575597, MAE: 0.94739926\n",
      "Epoch 385: MSE: 2.4921846, MAE: 0.9003932\n",
      "Epoch 386: MSE: 2.4164274, MAE: 0.91982543\n",
      "Epoch 387: MSE: 2.5187912, MAE: 0.91724086\n",
      "Epoch 388: MSE: 2.4504337, MAE: 0.92370415\n",
      "Epoch 389: MSE: 2.619649, MAE: 0.91085726\n",
      "Epoch 390: MSE: 2.3063135, MAE: 0.9067628\n",
      "Epoch 391: MSE: 2.4182894, MAE: 0.91880196\n",
      "Epoch 392: MSE: 2.4177794, MAE: 0.9106687\n",
      "Epoch 393: MSE: 2.406429, MAE: 0.9108343\n",
      "Epoch 394: MSE: 2.429041, MAE: 0.929051\n",
      "Epoch 395: MSE: 2.4437292, MAE: 0.9136773\n",
      "Epoch 396: MSE: 2.3382561, MAE: 0.9288531\n",
      "Epoch 397: MSE: 2.4104004, MAE: 0.9146704\n",
      "Epoch 398: MSE: 2.5630467, MAE: 0.92204434\n",
      "Epoch 399: MSE: 2.2167084, MAE: 0.89655083\n",
      "Epoch 400: MSE: 2.3845942, MAE: 0.9179224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401: MSE: 2.5129042, MAE: 0.89285874\n",
      "Epoch 402: MSE: 2.432356, MAE: 0.8989935\n",
      "Epoch 403: MSE: 2.391878, MAE: 0.9090339\n",
      "Epoch 404: MSE: 2.382053, MAE: 0.9091116\n",
      "Epoch 405: MSE: 2.568975, MAE: 0.9029995\n",
      "Epoch 406: MSE: 2.3723063, MAE: 0.89014095\n",
      "Epoch 407: MSE: 2.3531203, MAE: 0.91543454\n",
      "Epoch 408: MSE: 2.2610624, MAE: 0.9059733\n",
      "Epoch 409: MSE: 2.3803353, MAE: 0.8947563\n",
      "Epoch 410: MSE: 2.3491175, MAE: 0.8957232\n",
      "Epoch 411: MSE: 2.368956, MAE: 0.8814404\n",
      "Epoch 412: MSE: 2.158277, MAE: 0.88086987\n",
      "Epoch 413: MSE: 2.353748, MAE: 0.9367809\n",
      "Epoch 414: MSE: 2.4315088, MAE: 0.90372974\n",
      "Epoch 415: MSE: 2.366479, MAE: 0.888922\n",
      "Epoch 416: MSE: 2.3756168, MAE: 0.8951221\n",
      "Epoch 417: MSE: 2.2261536, MAE: 0.8750168\n",
      "Epoch 418: MSE: 2.504664, MAE: 0.91973174\n",
      "Epoch 419: MSE: 2.1368024, MAE: 0.87866914\n",
      "Epoch 420: MSE: 2.2465808, MAE: 0.88729155\n",
      "Epoch 421: MSE: 2.420235, MAE: 0.88819325\n",
      "Epoch 422: MSE: 2.234766, MAE: 0.89463145\n",
      "Epoch 423: MSE: 2.2678533, MAE: 0.893333\n",
      "Epoch 424: MSE: 2.3503175, MAE: 0.89011544\n",
      "Epoch 425: MSE: 2.3539062, MAE: 0.87687075\n",
      "Epoch 426: MSE: 2.3404808, MAE: 0.8806616\n",
      "Epoch 427: MSE: 2.2609866, MAE: 0.8846789\n",
      "Epoch 428: MSE: 2.268207, MAE: 0.8793957\n",
      "Epoch 429: MSE: 2.2946806, MAE: 0.88659585\n",
      "Epoch 430: MSE: 2.2820086, MAE: 0.86499894\n",
      "Epoch 431: MSE: 2.5118573, MAE: 0.88876474\n",
      "Epoch 432: MSE: 2.248334, MAE: 0.881676\n",
      "Epoch 433: MSE: 2.1831996, MAE: 0.8625484\n",
      "Epoch 434: MSE: 2.117667, MAE: 0.8847401\n",
      "Epoch 435: MSE: 2.4408975, MAE: 0.9031277\n",
      "Epoch 436: MSE: 2.2802916, MAE: 0.8764304\n",
      "Epoch 437: MSE: 2.261163, MAE: 0.8637206\n",
      "Epoch 438: MSE: 2.1413016, MAE: 0.8601023\n",
      "Epoch 439: MSE: 2.2022424, MAE: 0.88821167\n",
      "Epoch 440: MSE: 2.324405, MAE: 0.87576336\n",
      "Epoch 441: MSE: 2.1366968, MAE: 0.8587043\n",
      "Epoch 442: MSE: 2.3173192, MAE: 0.89453673\n",
      "Epoch 443: MSE: 2.1439188, MAE: 0.8620511\n",
      "Epoch 444: MSE: 2.2326522, MAE: 0.86518383\n",
      "Epoch 445: MSE: 2.2584841, MAE: 0.8704668\n",
      "Epoch 446: MSE: 2.313962, MAE: 0.8895412\n",
      "Epoch 447: MSE: 2.1900725, MAE: 0.86601245\n",
      "Epoch 448: MSE: 2.294421, MAE: 0.86072356\n",
      "Epoch 449: MSE: 2.0444243, MAE: 0.8473688\n",
      "Epoch 450: MSE: 2.2126932, MAE: 0.8631451\n",
      "Epoch 451: MSE: 2.041096, MAE: 0.84794235\n",
      "Epoch 452: MSE: 2.1955543, MAE: 0.8828868\n",
      "Epoch 453: MSE: 2.2266047, MAE: 0.8502518\n",
      "Epoch 454: MSE: 2.218089, MAE: 0.8612813\n",
      "Epoch 455: MSE: 2.2374613, MAE: 0.86942255\n",
      "Epoch 456: MSE: 2.2505922, MAE: 0.85639423\n",
      "Epoch 457: MSE: 2.2981849, MAE: 0.8617755\n",
      "Epoch 458: MSE: 2.1053872, MAE: 0.84646475\n",
      "Epoch 459: MSE: 2.195998, MAE: 0.86850095\n",
      "Epoch 460: MSE: 2.2938335, MAE: 0.84951836\n",
      "Epoch 461: MSE: 2.090219, MAE: 0.87599456\n",
      "Epoch 462: MSE: 2.2194052, MAE: 0.8761467\n",
      "Epoch 463: MSE: 2.239395, MAE: 0.8856499\n",
      "Epoch 464: MSE: 2.1520362, MAE: 0.8592015\n",
      "Epoch 465: MSE: 2.1824365, MAE: 0.8492628\n",
      "Epoch 466: MSE: 2.0233774, MAE: 0.86881644\n",
      "Epoch 467: MSE: 2.133731, MAE: 0.8765603\n",
      "Epoch 468: MSE: 2.252743, MAE: 0.847372\n",
      "Epoch 469: MSE: 2.127872, MAE: 0.8702631\n",
      "Epoch 470: MSE: 2.119335, MAE: 0.85358435\n",
      "Epoch 471: MSE: 2.0426474, MAE: 0.8433602\n",
      "Epoch 472: MSE: 2.0978186, MAE: 0.8508818\n",
      "Epoch 473: MSE: 2.0720613, MAE: 0.84921527\n",
      "Epoch 474: MSE: 2.1438372, MAE: 0.83753645\n",
      "Epoch 475: MSE: 2.058097, MAE: 0.83606493\n",
      "Epoch 476: MSE: 2.1719975, MAE: 0.8697869\n",
      "Epoch 477: MSE: 2.1055815, MAE: 0.83109885\n",
      "Epoch 478: MSE: 1.9607046, MAE: 0.8375965\n",
      "Epoch 479: MSE: 1.9299698, MAE: 0.84505475\n",
      "Epoch 480: MSE: 2.089106, MAE: 0.86018395\n",
      "Epoch 481: MSE: 2.0365095, MAE: 0.8213502\n",
      "Epoch 482: MSE: 2.1231318, MAE: 0.84997886\n",
      "Epoch 483: MSE: 1.9681525, MAE: 0.8236781\n",
      "Epoch 484: MSE: 2.0448296, MAE: 0.84244734\n",
      "Epoch 485: MSE: 2.0632114, MAE: 0.8476881\n",
      "Epoch 486: MSE: 2.1391263, MAE: 0.8267794\n",
      "Epoch 487: MSE: 2.0280828, MAE: 0.8267915\n",
      "Epoch 488: MSE: 2.0609512, MAE: 0.83775276\n",
      "Epoch 489: MSE: 2.0743194, MAE: 0.83239836\n",
      "Epoch 490: MSE: 2.1214716, MAE: 0.8359094\n",
      "Epoch 491: MSE: 1.9868475, MAE: 0.82772416\n",
      "Epoch 492: MSE: 1.9386175, MAE: 0.861639\n",
      "Epoch 493: MSE: 1.9838738, MAE: 0.83209664\n",
      "Epoch 494: MSE: 2.0864275, MAE: 0.8337761\n",
      "Epoch 495: MSE: 1.9892896, MAE: 0.82996\n",
      "Epoch 496: MSE: 2.0080514, MAE: 0.84834325\n",
      "Epoch 497: MSE: 1.9921806, MAE: 0.8422906\n",
      "Epoch 498: MSE: 2.052608, MAE: 0.8382149\n",
      "Epoch 499: MSE: 2.0176854, MAE: 0.82452995\n",
      "Epoch 500: MSE: 1.8474998, MAE: 0.8174377\n"
     ]
    }
   ],
   "source": [
    "for epoch in 1...epochCount {\n",
    "    var epochLoss: Float = 0\n",
    "    var epochMAE: Float = 0\n",
    "    var batchCount: Int = 0\n",
    "    var batchArray = Array(repeating: false, count: numberOfBatch)\n",
    "    for batch in 0..<numberOfBatch {\n",
    "        var r = batch\n",
    "        if shuffle {\n",
    "            while true {\n",
    "                r = Int.random(in: 0..<numberOfBatch)\n",
    "                if !batchArray[r] {\n",
    "                    batchArray[r] = true\n",
    "                    break\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        let batchStart = r * batchSize\n",
    "        let batchEnd = min(numTrainRecords, batchStart + batchSize)\n",
    "        let (loss, grad) = model.valueWithGradient { (model: RegressionModel) -> Tensor<Float> in\n",
    "            let multiInput = MultiInputs(numerical: [XNumericalTrain[batchStart..<batchEnd]],\n",
    "                                         categorical: [XCategoricalTrain[0][batchStart..<batchEnd],\n",
    "                                                       XCategoricalTrain[1][batchStart..<batchEnd]])\n",
    "            let logits = model(multiInput)\n",
    "            return meanSquaredError(predicted: logits, expected: YTrain[batchStart..<batchEnd])\n",
    "        }\n",
    "        optimizer.update(&model, along: grad)\n",
    "        \n",
    "        let multiInput = MultiInputs(numerical: [XNumericalTrain[batchStart..<batchEnd]],\n",
    "                                     categorical: [XCategoricalTrain[0][batchStart..<batchEnd],\n",
    "                                                   XCategoricalTrain[1][batchStart..<batchEnd]])\n",
    "        let logits = model(multiInput)\n",
    "        epochMAE += mae(predictions: logits, truths: YTrain[batchStart..<batchEnd])\n",
    "        epochLoss += loss.scalarized()\n",
    "        batchCount += 1\n",
    "    }\n",
    "    epochMAE /= Float(batchCount)\n",
    "    epochLoss /= Float(batchCount)\n",
    "\n",
    "    print(\"Epoch \\(epoch): MSE: \\(epochLoss), MAE: \\(epochMAE)\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10480358, MAE: 0.022593323\r\n"
     ]
    }
   ],
   "source": [
    "Context.local.learningPhase = .inference\n",
    "\n",
    "let multiInputTest = MultiInputs(numerical: [XNumericalTest],\n",
    "                                 categorical: [XCategoricalTest[0],\n",
    "                                               XCategoricalTest[1]])\n",
    "\n",
    "let prediction = model(multiInputTest)\n",
    "\n",
    "let predictionMse = meanSquaredError(predicted: prediction, expected: YTest).scalarized()/Float(numTestRecords)\n",
    "let predictionMae = mae(predictions: prediction, truths: YTest)/Float(numTestRecords)\n",
    "\n",
    "print(\"MSE: \\(predictionMse), MAE: \\(predictionMae)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fkf29HLlohIP"
   },
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2] [9, 5]\r\n"
     ]
    }
   ],
   "source": [
    "print(model.embedding1.embeddings.shape, model.embedding2.embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "let coremlModel = Model(version: 4,\n",
    "                        shortDescription: \"Regression\",\n",
    "                        author: \"Jacopo Mangiavacchi\",\n",
    "                        license: \"MIT\",\n",
    "                        userDefined: [\"SwiftCoremltoolsVersion\" : \"0.0.6\"]) {\n",
    "    Input(name: \"numericalInput\", shape: [11])\n",
    "    Input(name: \"categoricalInput1\", shape: [1])\n",
    "    Input(name: \"categoricalInput2\", shape: [1])\n",
    "    Output(name: \"output\", shape: [1])\n",
    "    NeuralNetwork {\n",
    "        Embedding(name: \"embedding1\",\n",
    "                     input: [\"categoricalInput1\"],\n",
    "                     output: [\"outEmbedding1\"],\n",
    "                     weight: model.embedding1.embeddings.transposed().flattened().scalars,\n",
    "                     inputDim: 2,\n",
    "                     outputChannels: 2)\n",
    "        Permute(name: \"permute1\",\n",
    "                     input: [\"outEmbedding1\"],\n",
    "                     output: [\"outPermute1\"],\n",
    "                     axis: [2, 1, 0, 3])\n",
    "        Flatten(name: \"flatten1\",\n",
    "                     input: [\"outPermute1\"],\n",
    "                     output: [\"outFlatten1\"],\n",
    "                     mode: .last)\n",
    "        Embedding(name: \"embedding2\",\n",
    "                     input: [\"categoricalInput2\"],\n",
    "                     output: [\"outEmbedding2\"],\n",
    "                     weight: model.embedding2.embeddings.transposed().flattened().scalars,\n",
    "                     inputDim: 9,\n",
    "                     outputChannels: 5)\n",
    "        Permute(name: \"permute2\",\n",
    "                     input: [\"outEmbedding2\"],\n",
    "                     output: [\"outPermute2\"],\n",
    "                     axis: [2, 1, 0, 3])\n",
    "        Flatten(name: \"flatten2\",\n",
    "                     input: [\"outPermute2\"],\n",
    "                     output: [\"outFlatten2\"],\n",
    "                     mode: .last)\n",
    "        Concat(name: \"concat\",\n",
    "                     input: [\"numericalInput\", \"outFlatten1\", \"outFlatten2\"],\n",
    "                     output: [\"outConcat\"])\n",
    "        InnerProduct(name: \"dense1\",\n",
    "                     input: [\"outConcat\"],\n",
    "                     output: [\"outDense1\"],\n",
    "                     weight: model.allInputConcatLayer.weight.transposed().flattened().scalars,\n",
    "                     bias: model.allInputConcatLayer.bias.flattened().scalars,\n",
    "                     inputChannels: 11 + 2 + 5,\n",
    "                     outputChannels: 64)\n",
    "        ReLu(name: \"Relu1\",\n",
    "             input: [\"outDense1\"],\n",
    "             output: [\"outRelu1\"])\n",
    "        InnerProduct(name: \"dense2\",\n",
    "                     input: [\"outRelu1\"],\n",
    "                     output: [\"outDense2\"],\n",
    "                     weight: model.hiddenLayer.weight.transposed().flattened().scalars,\n",
    "                     bias: model.hiddenLayer.bias.flattened().scalars,\n",
    "                     inputChannels: 64,\n",
    "                     outputChannels: 32)\n",
    "        ReLu(name: \"Relu2\",\n",
    "             input: [\"outDense2\"],\n",
    "             output: [\"outRelu2\"])\n",
    "        InnerProduct(name: \"dense3\",\n",
    "                     input: [\"outRelu2\"],\n",
    "                     output: [\"output\"],\n",
    "                     weight: model.outputLayer.weight.transposed().flattened().scalars,\n",
    "                     bias: model.outputLayer.bias.flattened().scalars,\n",
    "                     inputChannels: 32,\n",
    "                     outputChannels: 1)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "let coreMLData = coremlModel.coreMLData\n",
    "try! coreMLData!.write(to: URL(fileURLWithPath: \"../model/s4tf_house_simplified_trained_model.mlmodel\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  -0.4000649,  -0.49060422,  -0.37006438,  -0.29516807,    0.2773472,     1.021877,\r\n",
      "   -0.6626676,  -0.11198587,    1.1625932,   0.40813962, -0.047246937] [0] [4] => [19.8]\r\n",
      "[   2.421373, -0.49060422,  0.99975175,   1.2359748,   -2.246887,    1.124838,  -1.1245025,\r\n",
      "   1.5638397,   0.8357405,  0.42682302,     2.17172] [0] [8] => [10.5]\r\n",
      "[-0.32639477,  0.38105497,  -1.0291269,   0.7851385,  -0.9889262, -0.19590291,  -0.8761533,\r\n",
      " -0.82510316,  -2.5261788,   0.3761753, -0.29949686] [0] [4] => [22.8]\r\n"
     ]
    }
   ],
   "source": [
    "print(XNumericalTest[0], XCategoricalTest[0][0], XCategoricalTest[1][0], \"=>\", YTest[0])\n",
    "print(XNumericalTest[17], XCategoricalTest[0][17], XCategoricalTest[1][17], \"=>\", YTest[17])\n",
    "print(XNumericalTest[87], XCategoricalTest[0][87], XCategoricalTest[1][87], \"=>\", YTest[87])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: [21.99591]\r\n"
     ]
    }
   ],
   "source": [
    "Context.local.learningPhase = .inference\n",
    "\n",
    "let numerical = [XNumericalTest[0].reshaped(to: TensorShape([1, 11]))]\n",
    "let cat1 = XCategoricalTest[0][0].reshaped(to: TensorShape([1, 1]))\n",
    "let cat2 = XCategoricalTest[1][0].reshaped(to: TensorShape([1, 1]))\n",
    "let categorical = [cat1, cat2]\n",
    "\n",
    "let multiInputTest = MultiInputs(numerical: numerical,\n",
    "                                 categorical: categorical)\n",
    "\n",
    "let prediction = model(multiInputTest)\n",
    "\n",
    "print(\"0: \\(prediction[0])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "func predictTestRecord(_ record: Int) {\n",
    "    Context.local.learningPhase = .inference\n",
    "\n",
    "    let numerical = [XNumericalTest[record].reshaped(to: TensorShape([1, 11]))]\n",
    "    let cat1 = XCategoricalTest[0][record].reshaped(to: TensorShape([1, 1]))\n",
    "    let cat2 = XCategoricalTest[1][record].reshaped(to: TensorShape([1, 1]))\n",
    "    let categorical = [cat1, cat2]\n",
    "\n",
    "    let multiInputTest = MultiInputs(numerical: numerical,\n",
    "                                     categorical: categorical)\n",
    "\n",
    "    let prediction = model(multiInputTest)\n",
    "\n",
    "    print(\"=== Test Record \\(record) ===\")\n",
    "    print(\"Numerical Input: \\(XNumericalTest[record])\")\n",
    "    print(\"Categorical Input: \\(XCategoricalTest[0][record]) \\(XCategoricalTest[1][record])\")\n",
    "    print(\"Prediction: \\(prediction[0])\")\n",
    "    print(\"Y: \\(YTest[record])\")\n",
    "    print(\"------------------\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Test Record 0 ===\n",
      "Numerical Input: [  -0.4000649,  -0.49060422,  -0.37006438,  -0.29516807,    0.2773472,     1.021877,\n",
      "   -0.6626676,  -0.11198587,    1.1625932,   0.40813962, -0.047246937]\n",
      "Categorical Input: [0] [4]\n",
      "Prediction: [21.99591]\n",
      "Y: [19.8]\n",
      "------------------\n",
      "=== Test Record 17 ===\n",
      "Numerical Input: [   2.421373, -0.49060422,  0.99975175,   1.2359748,   -2.246887,    1.124838,  -1.1245025,\n",
      "   1.5638397,   0.8357405,  0.42682302,     2.17172]\n",
      "Categorical Input: [0] [8]\n",
      "Prediction: [6.3390083]\n",
      "Y: [10.5]\n",
      "------------------\n",
      "=== Test Record 87 ===\n",
      "Numerical Input: [-0.32639477,  0.38105497,  -1.0291269,   0.7851385,  -0.9889262, -0.19590291,  -0.8761533,\n",
      " -0.82510316,  -2.5261788,   0.3761753, -0.29949686]\n",
      "Categorical Input: [0] [4]\n",
      "Prediction: [25.197638]\n",
      "Y: [22.8]\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "predictTestRecord(0)\n",
    "predictTestRecord(17)\n",
    "predictTestRecord(87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "S4TF_House.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
